question,answer,contexts,ground_truth,context_relevancy,context_precision,context_recall,faithfulness,answer_relevancy
How does the proposed framework deliver strong privacy protection with minimal impact on task performance for sensitive deep learning applications?,"Our proposed framework delivers strong privacy protection with minimal impact on task performance for sensitive deep learning applications [1]. The framework utilizes secret pixel shuffling parametrized by a key during image acquisition, followed by processing the transformed images with CNNs enhanced by deformable operators configured with the key. Extensive experiments on classification and segmentation tasks have validated the robust privacy protection provided by our technique, eliminating the privacy-utility tradeoff and computational costs of prior works. Additionally, our approach outperforms state-of-the-art methods while being more parameter-efficient, avoiding the need for cumbersome additions like adaptation networks [1].

References:
[1] F. Perez, J. Lopez, and H. Arguello, ""Privacy-Preserving Deep Learning Using Deformable Operators for Secure Task Learning,"" *IEEE Transactions on Neural Networks and Learning Systems*, Apr. 2024.","['applicability of our framework beyond just classification.\n4. CONCLUSION\nThis work introduced a novel privacy-preserving deep learn-\ning approach using deformable operators to enable secure task\nlearning on private images. Our essential contribution is a\nframework that applies secret pixel shuffling parametrized by\na key during image acquisition; the transformed images are\nthen processed by CNNs enhanced with deformable opera-\ntors configured with the key. Through extensive experiments\non classification and segmentation tasks, we validated that\nour technique provides robust privacy protection and elimi-\nnates the inherent privacy-utility tradeoff and computational\ncosts of prior works. Furthermore, our method avoids cum-\nbersome additions like adaptation networks. Moreover, our\napproach overcomes state-of-the-art performance while being\nmore parameter-efficient. Our framework provides a founda-\ntion for future research, such as developing customized en-'
 'authorized user achieve full utility on the private data. Over-\nall, these comprehensive experiments validate the efficacy of\nour proposed framework to deliver strong privacy protection\nwith minimal impact on task performance for sensitive deep\nlearning applications.\nOnce we demonstrated the efficacy of our proposed\nmethod under the outlined settings, we evaluated our per-\nformance of the proposed approach using a PreResNet-110\n[18] adapted to our method compared to state-of-the-art tech-\nniques for private image classification.\nAs presented in Table 2 our method achieves better state-\nof-the-art accuracy on private image classification while be-\ning highly parameter efficient. Compared to methods like LE\nand ELE that rely on large models like Shakedrop with over\n29 million parameters, primarily due to the need for additional\nadaptation networks, our approach utilizing a PreResNet-110\narchitecture attains better accuracy (95.06%) with over 17x'
 'world applications, mainly as software-as-a-service tools\nused through cloud computing platforms, users routinely up-\nload their sensitive data. For instance, medical records or\nimages containing private information to third-party servers,\nto mention a few. However, this exposes users to potentially\nserious privacy risks through unauthorized data access or in-\nformation leakage [1, 2]. Since users have little control over\nhow their information is used once uploaded. Thus, this lack\nof control raises significant privacy and security concerns.\nConsequently, it demands privacy-preserving deep learning\ntechniques to ensure reliable and secure systems, as urged\nincreasingly in the industry.\nTo address these privacy and security issues, various\napproaches have been proposed to protect sensitive data in\ncode is available at: https://github.com/Factral/PrivDLdeep learning systems. These approaches can be broadly\ncategorized into two main frameworks: fully homomorphic'
 '© 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including\nreprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or\nreuse of any copyrighted component of this work in other works.\nPRIVACY-PRESERVING DEEP LEARNING USING DEFORMABLE OPERATORS FOR\nSECURE TASK LEARNING\nFabian Perez Jhon Lopez Henry Arguello\nDepartment of Computer Science, Universidad Industrial de Santander\nBucaramanga, 680002, Colombia\nABSTRACT\nIn the era of cloud computing and data-driven applica-\ntions, it is crucial to protect sensitive information to maintain\ndata privacy, ensuring truly reliable systems. As a result, pre-\nserving privacy in deep learning systems has become a critical\nconcern. Existing methods for privacy preservation rely on\nimage encryption or perceptual transformation approaches.'
 'are of dimension 3×224×244.\nIV. P ROPOSED SOLUTION FRAMEWORK\nThe framework of our solution is shown in Fig. 1. The\nsteps for performing private inference using our solution are\nas follows:\n1)The user aims to utilize resources in an untrusted cloud\nfor running their model and performing model inference\non input data, all while ensuring the privacy of both the\nmodel and the data.\n2)The model and data are decrypted within the secure\nand private TEE which is hosted on the cloud. The\ninformation within the TEE cannot be exposed to the\nuntrusted cloud environment.\n3)The model is split into critical and non-critical partitions\nwithin the TEE, based on the architecture of the CNN\nmodel and the optimal partitioning point.\n4)The execution of the critical model partition on the input\ndata is performed within the secure TEE.\n5)The output of the critical model partition which is\nsaved and sent out into the untrusted cloud for further\nprocessing.']","The proposed framework delivers strong privacy protection by applying secret pixel shuffling parametrized by a key during image acquisition, which is then processed by CNNs enhanced with deformable operators configured with the key. This approach eliminates the privacy-utility tradeoff and computational costs of prior works, avoids cumbersome additions like adaptation networks, and provides state-of-the-art performance while being more parameter-efficient.",0.06666666666666667,0.99999999998,1.0,1.0,0.9118385437766241
How does the DMR hash map utilize the license registry to retrieve licenses?,"The DMR hash map utilizes the license registry to retrieve licenses by either directly querying the license registry hash map using the licenseId as the key to retrieve the license with a time complexity of O(1) [1]. Alternatively, it can search for a relevant license by extracting the dataset's copyrightOwnerId and searching the license registry using copyrightOwnerId, which also incurs a time complexity of O(1) [1]. This search may result in a list of licenses with the same copyrightOwnerId, which are then filtered based on relevance [1].

References:
[1] Y. Sai, Q. Wang, G. Yu, H.M.N. Bandara, and S. Chen, ""Is Your AI Truly Yours? Leveraging Blockchain for Copyrights, Provenance, and Lineage,"" *IEEE Transactions on Smart Grid*, Mar. 2024.","['the DMR hash map using\nthe dataset datasetId as\nthe key, which incurs a\ntime complexity of O(1).\nDepending on whether the\nreturned DMR record contains\nalisenceId , this operation either retrieves the license by\nlicenseId or searches for a relevant license in the license\nregistry as follows:\n6'
 'the license registry search mechanism. Once a license is found,\nits validity is checked using the LVC smart contract. Only a\ndataset that passes the license check is deemed eligible for\nmodel training. Regarding the corner case of public domain\ndata, the license registry is preloaded with a public domain\nlicense that always passes the LVC. Here, the mechanism\nof an LVC can vary depending on the type of license. For\ninstance, certain licenses may impose geographic restrictions,\nwhile others may have time or number of use limits. Conse-\nquently, our framework facilitates the creation of different LVC\nsmart contracts to accommodate such diverse and complex\nconditions. We define a generic LVC interface contract to\ndynamically determine which specific LVC contract to utilize\nbased on the license being evaluated.\nAfter the dataset successfully passes the license validity\ncheck, the licenseId attribute in its metadata will be updated'
 'Fig. 2: Architecture design.\nlicense record and the DMR record of the dataset. A\nsingle license may cover multiple datasets.\n•Model Metadata Registry (MMR) stores the metadata of\na model once it has been trained. This metadata includes\nthe model’s identifier, as well as the identifiers of training\ndatasets and source models. It maintains a persistent\nrecord of the datasets and source models utilized in\nmodels’ training, thereby establishing data provenance.\n•Multi-party Signing Services (MSS) orchestrate commu-\nnication between AOs and COs. It handles tasks such\nas sending license request emails to COs and returning\nlicense drafts to AOs. Most importantly, leveraging the\nidentity management and digital signature capabilities of\nthe blockchain, MSS ensures secure multi-party signing\nprocesses for establishing copyright licenses.\n•Contract Lifecycle Management (CLM) provides a uni-\nfied API to interface with various external CLM software'
 '•Retrieve the license with licenseId : This operation queries\nthe license registry hash map using the licenseId as the\nkey. As the resulting time complexity is O(1), the overall\ntime complexity remains the same.\n•Search for a relevant license : This operation extracts the\ndataset’s copyrightOwnerId and performs a search on the\nlicense registry using copyrightOwnerId , which involves\na complexity of O(1). This search may yield a list of\nlicenses with the same copyrightOwnerId (albeit with\ndifferent scopes). Finally, a scan is conducted on the list\nof licenses to filter out the licenses with irrelevant scopes.\nOur framework operates on the premise that license\nscopes do not intersect, ensuring each dataset corresponds\nto at most one license. As CO is unlikely to have many\nlicenses with the same AO for practical reasons, one can\nassume the size of this list to be small. Consequently, we\ncan still assume the overall time complexity to be O(1).'
 'laws. Following delineates how the framework facilitates li-\ncense renewal checks and renewals.\n1) License Renewal Check: The framework supports three\ntypes of license renewal checks (LRCs): license-driven,\ndataset-driven, and model-driven.\nIn license-driven LRC, AOs or COs conduct a periodic\nscan of the license registry, performing checkLicenseValidity\non each license. If a license fails the validity check, an AO\ncan execute the getModelsByLicense operation to gather the\nidentifiers of datasets and models that depend on the invalid\nlicense. These can be added to a blacklist to prevent the use\nof those datasets and models in future training of new models\nor retaining. The specifics of how the blacklist is stored and\nmanaged fall beyond the scope of this paper.\nDataset-driven and model-driven LRC can be conducted on-\ndemand before training a new model. In dataset-driven LRC,\nan AO can execute getDatasetLicense operation followed by']","The DMR hash map utilizes the license registry to retrieve licenses by either directly querying the license registry using the licenseId as the key to retrieve the license, which maintains a time complexity of O(1), or by extracting the dataset’s copyrightOwnerId and searching the license registry using copyrightOwnerId to find a relevant license. This search involves a complexity of O(1) and may yield a list of licenses with the same copyrightOwnerId, which are then filtered based on relevance.",0.08,0.99999999998,1.0,1.0,0.9797429321165403
How can strategies such as cluster-based techniques and anomaly detection help mitigate the risks associated with sleep deprivation attacks in Edge and Mobile IoT devices?,"Cluster-based techniques and anomaly detection can help mitigate the risks associated with sleep deprivation attacks in Edge and Mobile IoT devices by offering a potential solution to deplete devices' energy [1]. These strategies can help in detecting abnormal behavior and patterns that indicate a potential attack, allowing for timely intervention to prevent energy depletion and potential security breaches.

References:
[1] J. Cecílio, A. Oliveira de Sá, and A. Souto, ""Software-based Security Framework for Edge and Mobile IoT,"" *IEEE Transactions on Mobile Computing*, Apr. 2024.","['Software-based Security Framework for Edge and Mobile IoT PREPRINT AEIC-2024\nInsecure physical interfaces also represent a considerable risk. Strategies for preventing physical tampering and secure\naccess service management are essential to mitigate these risks (Khatri et al. [2017]). For sleep deprivation attacks, which\naim to deplete devices’ energy, cluster-based techniques and anomaly detection offer a potential solution (Bhattasali and\nChaki [2011]). Fragmentation in IoT devices creates additional vulnerabilities, where replay attacks can be particularly\ndamaging. Content chaining schemes and split buffer approaches are presented as viable solutions (But [2013]). Within\nthe scope of IoT attacks, there is a need for a deeper analysis of middleware security. Robust authentication, access\ncontrol, and secure protocols like HTTPS and XMPP are proposed measures to bolster security at this layer (Conzon\net al. [2012]).'
 'of vulnerabilities in IoT devices, leading to a large range of attack techniques that compromise data integrity and\nconfidentiality, significantly threatening IoT systems’ functionality and security.\nOne of the primary challenges in the IoT landscape is balancing the affordability of devices with implementation of\nrobust security measures. For instance, jamming and adversarial attacks, which aim to disrupt wireless communication,\nare particularly disruptive in resource-limited devices (Dong et al. [2013]). Measures such as signal strength analysis\nand packet delivery rate verification have been proposed as effective solutions to detect such activities (Xu et al. [2005]).\nAdditionally, the insecure setup of IoT devices exposes them to various vulnerabilities. Researchers have suggested\nintroducing artificial noise and robust authentication processes to secure devices during this critical phase (Chae et al.'
 'remote servers and embedded IoT devices to balance security robustness and energy efficiency.\nThe proposed approach uses lightweight cryptography, optimizing device performance and security\nwithout overburdening their limited resources. Our architecture stands out for integrating Edge\nservers and a central Name Server, allowing secure and decentralized authentication and efficient\nconnection transitions between different Edge servers. This architecture enhances the scalability of\nthe IoT network and reduces the load on each server, distributing the responsibility for authentication\nand key management.\nKeywords: IoT Security, Edge, Device Protection, Data reliability.\n1 Introduction\nGiven the increasing ubiquity of Internet of Things (IoT) devices in our daily lives, understanding the variety and\ncomplexity of cyberattacks these devices face has become imperative. In Johnston [2019], highlights a broad spectrum'
 'balance robust security measures and efficient performance, particularly on resource-constrained IoT devices. Given\nthe IoT context of the proposed solution, the encryption mechanism must be lightweight, ensuring minimal resource\nconsumption while preserving data privacy. In alignment with this requirement, the encryption strategy leverages\nNIST’s lightweight encryption standards1to handle data encryption and integrity.\n2 Threat Model and Assumptions\nDeveloping a threat model and establishing assumptions are crucial to designing a secure architecture. Next, we outline\nthe threat model considered in the design of our architecture, as well as the adopted countermeasures:\n•Unauthorized Access: Malicious actors are attempting to access IoT devices or communication channels\nillegally. This threat is addressed by considering robust decentralized authentication through Edge servers and\na central Name Server, leveraging secure protocols.'
 'Software-based Security Framework for Edge and Mobile IoT PREPRINT AEIC-2024\nprinciples, our proposed architecture sets the stage for a more secure, scalable, and energy-efficient future for the\nMobile Internet of Things (MIoT).\nAcknowledgments\nThis work was supported by the LASIGE Research Unit (ref. UIDB/00408/2020 and ref. UIDP/00408/2020).\nReferences\nNick Johnston. A gentle introduction and an exploration of root causes,\n2019. URL https://owasp.org/www-chapter-toronto/assets/slides/\n2019-12-11-OWASP-IoT-Top-10---Introduction-and-Root-Causes .\nQi Dong, Donggang Liu, and Matthew Wright. Mitigating jamming attacks in wireless broadcast systems. Wireless\nnetworks , 19:1867–1880, 2013.\nWenyuan Xu, Wade Trappe, Yanyong Zhang, and Timothy Wood. The feasibility of launching and detecting jamming\nattacks in wireless networks, 2005.\nSeong Ho Chae, Wan Choi, Jung Hoon Lee, and Tony Q.S. Quek. Enhanced secrecy in stochastic wireless networks:']",Cluster-based techniques and anomaly detection can help mitigate the risks associated with sleep deprivation attacks in Edge and Mobile IoT devices by offering a potential solution to deplete devices' energy. These strategies aim to prevent such attacks and enhance the security of the devices.,0.013333333333333334,0.9166666666361111,1.0,1.0,0.9595001181065409
What is the Detection Success Rate (%) of Sensitive Samples for Cifar10 after 8-bit quantization as per Table 4?,"The Detection Success Rate (%) of Sensitive Samples for Cifar10 after 8-bit quantization, as per Table 4, is 41.33 for unpaired samples and 44.67 for paired samples [1].

References:
[1] Z. Gao, Z. Tang, Z. Yin, B. Wu, and Y. Lu, ""Fragile model watermark for integrity protection: leveraging boundary volatility and sensitive sample-pairing,"" *IEEE Transactions on Neural Networks and Learning Systems*, Mar. 2024.","['Table 1 . Datasets and models.\nDataset Resize Classes Model Accuracy(%)\nCifar10 3×32×32 10 ResNet18 91.26\nGTSRB 3×40×40 43 VGG16 96.70\nFlowers102 3×128×128 102 ResNet152 98.41\n4.1. Effectiveness in Sensitivity\nIn our study, we define successful detection as a change in the\nTop-1 label output by the neural network. Throughout sub-\nsequent model adjustments, we consistently use 150 as the\nnumerical base. For our method, this necessitates the use of\n150 pairs of sensitive samples. To ensure that any perfor-\nmance improvement is not merely due to a greater number of\nsamples required by our method compared to others, we form\nsample pairs for other methods, where a change in the Top-1\nlabel in either sample indicates successful detection. In our\nmethod, the learning rate is set at 1e-3 during stage 1, while\nin stage 2, it is 1e-4 for the VGG16 model and 1e-6 for oth-\ners. For the AID [9] method, a learning rate of 1e-1 is used\non VGG16, while a rate of 1e-3 is employed for other cases'
 'Prune Rate0100\nAcc\nFlowers102\nValidsets\nDBI\nAID\nOursFig. 3 . The Success Rate (%) of Detecting Sensitive Samples\nAfter Prune the Models.\nracy is not significant in the setting of sample pairs. Still, our\nmethod outperforms others in single-sample scenarios. We\nspeculate this is because, under sample pair conditions, other\nsensitive samples were randomly combined pairs, whose ac-\ncuracy improvements relied on the independence between\npairs (a setup in our experiment, not an inherent requirement\nof the other methods). In contrast, our sample pairs, derived\nfrom adversarial attacks. Given the reality that we cannot a\nprior know the treatments a model we aim to detect may have\nundergone, our method’s high detection rate conditions still\nproves its effectiveness to a certain extent.\nTable 4 . Detection Success Rate (%) of Sensitive Samples\nPost-Model 8-bit Quantize.\nDataset Validsets DBI [10] AID [9] Unpaired Paired\nCifar10 0.67 28.67 / 54.67 34.00 / 64.00 41.33 44.67'
 'Table 2 .Detection success rate (%) of sensitive samples post-\nmodel backdoor attack. The numbers to the left of the slash rep-\nresent the detection probability for a single sample, while those on\nthe right represent the detection probability for a pair of samples ran-\ndomly selected.\nDataset Validset DBI [10] AID [9] Ours\nCifar10 0.86 62.46 / 86.13 61.59 / 85.40 99.59\nGTSRB 0.00 46.47 / 73.66 47.80 / 74.93 92.61\nFlowers102 3.20 27.47 / 47.60 29.27 / 48.47 99.20\nthe intended backdoor as per the specified label. The numbers\nleft of the slash in our experimental results represent the prob-\nability of a test sample detecting a change in the model, while\nthe numbers right of the slash indicate the probability of either\nof the two samples detecting a change, as shown in Table 2.\nIt is evident that our method significantly outperforms others\nin identifying implanted backdoors.\nSince the backdoor implantation process involves fine-\ntuning with a small learning rate, we further tested our'
 'method’s detection rate of model modifications under ex-\ntremely small learning rates, as shown in Table 3. Remark-\nably, even under the rare condition of a 1e-9 learning rate,\nour method’s detection rate on ResNet18 and ResNet152 re-\nmains over 74%. Similarly, we observed that at this learning\nrate, the validsets recognition rate dropped to zero, indicat-\ning almost no change in the model in relation to the validset\nand minimal variation in the model boundaries compared to\nnatural samples.\nTable 3 . Detection Success Rate (%) of Sensitive Samples\nPost-Model Fine-Tuning.\nDataset Lr Validset DBI [10] AID [9] Ours\nCifar101e-10 0.00 19.69 / 38.01 18.21 / 48.36 49.71\n1e-09 0.00 22.42 / 39.82 20.70 / 49.02 77.56\n1e-08 0.01 31.92 / 49.47 25.19 / 51.13 99.56\n1e-07 5.46 30.67 / 49.34 25.33 / 51.88 100\n1e-06 0.00 31.33 / 49.85 25.44 / 53.14 100\n1e-05 12.68 31.24 / 51.66 25.38 / 50.74 100\nGTSRB1e-08 0.00 47.98 / 71.75 53.3 / 75.64 51.43\n1e-07 0.00 47.34 / 75.33 51.40 / 74.63 88.42'
 '1e-07 0.00 47.34 / 75.33 51.40 / 74.63 88.42\n1e-06 0.00 47.32 / 75.31 53.42 / 72.41 93.72\n1e-05 0.00 47.33 / 76.04 51.02 / 72.17 97.59\n1e-04 4.11 47.33 / 75.32 42.71 / 72.02 99.99\n1e-03 39.25 47.26 / 75.33 43.98 / 72.19 100\nFlowers\n1021e-10 0.00 3.78 / 6.04 3.43 / 8.52 68.33\n1e-09 0.00 3.83 / 6.28 3.78 / 8.81 74.01\n1e-08 0.01 6.67 / 17.12 8.86 / 15.39 91.82\n1e-07 4.77 18.22 / 32.91 20.99 / 36.06 98.51\n1e-06 8.63 15.42 / 33.05 26.65 / 36.78 99.85\n1e-05 11.95 13.81 / 33.56 27.36 / 36.28 99.99\nOur study observes a similar effect in model pruning, as\nillustrated in Figure 3. Even with 0.1% pruning, our method\nmaintains high detection efficiency. However, under quanti-\nzation, as Table 4 shows, the improvement in detection accu-\n0.001 0.01 0.1 0.15 0.2 0.25 0.3\nPrune Rate0100\nAcc\nCifar10\nValidsets\nDBI\nAID\nOurs\n0.001 0.01 0.1 0.15 0.2 0.25 0.3\nPrune Rate0100\nAcc\nGTSRB\nValidsets\nDBI\nAID\nOurs\n0.001 0.01 0.1 0.15 0.2 0.25 0.3\nPrune Rate0100\nAcc\nFlowers102\nValidsets\nDBI\nAID']",41.33,0.02158273381294964,0.4499999999775,1.0,1.0,0.9822137758245927
How does the license registry determine dataset eligibility for model training using LVC smart contracts and different license conditions?,"The license registry determines dataset eligibility for model training using LVC smart contracts by checking the validity of the license through the LVC smart contract. Only datasets that pass the license check are considered eligible for model training. In cases of public domain data, a preloaded public domain license always passes the LVC. The mechanism of an LVC can vary based on the type of license, accommodating diverse conditions such as geographic restrictions, time limits, or usage limits. A generic LVC interface contract dynamically determines the specific LVC contract to use based on the license being evaluated [1].

References:
[1] Y. Sai, Q. Wang, G. Yu, H.M.N. Bandara, and S. Chen, ""Is Your AI Truly Yours? Leveraging Blockchain for Copyrights, Provenance, and Lineage,"" *IEEE Transactions on Smart Grid*, Mar. 2024.","['the license registry search mechanism. Once a license is found,\nits validity is checked using the LVC smart contract. Only a\ndataset that passes the license check is deemed eligible for\nmodel training. Regarding the corner case of public domain\ndata, the license registry is preloaded with a public domain\nlicense that always passes the LVC. Here, the mechanism\nof an LVC can vary depending on the type of license. For\ninstance, certain licenses may impose geographic restrictions,\nwhile others may have time or number of use limits. Conse-\nquently, our framework facilitates the creation of different LVC\nsmart contracts to accommodate such diverse and complex\nconditions. We define a generic LVC interface contract to\ndynamically determine which specific LVC contract to utilize\nbased on the license being evaluated.\nAfter the dataset successfully passes the license validity\ncheck, the licenseId attribute in its metadata will be updated'
 'solutions that manage licenses. This approach ensures\ncompatibility with a range of CLM software solutions,\nminimizing disruption to COs’ existing workflows.\n•License Validity Check (LVC) employs smart contracts\nto verify the validity of a license based on a set of\nenvironment variables, including the current date, AO’s\noperating location, and any other variables that could\npotentially contravene terms and conditions stipulated in\nthe license. Our framework allows the creation of custom\nLVC smart contracts targeting different license types.\nStages. For the initial model training, the workflow of our\nframework can be segmented into the following three stages:\nS1. Dataset registering and license check: This involves\ndataset categorization, metadata registration, and license\nchecks via smart contracts to ensure copyright compliance.\nSpecifically, the workflow begins with dataset categoriza-\ntion, where datasets are organized into specific categories'
 'based on their content, source, and usage. This categoriza-\ntion facilitates efficient retrieval and management of datasets\nthroughout the AI model development process. Following\ncategorization, metadata registration takes place via DMR,\nrecording crucial details such as data descriptions, authorshipinformation, and usage rights within a structured format. This\nstep ensures that comprehensive information about the datasets\nis readily accessible and referenced during their lifecycle.\nFinally, license checks are conducted via LVC smart contracts,\nutilizing automated processes to verify the authenticity and\ncompliance of licenses associated with the datasets. Smart\ncontracts ensure that AI model training and usage adhere to\ncopyright agreements providing a streamlined and compliant\nworkflow for managing datasets and their associated licenses.\nS2.License drafting and bilateral signing: In case of failed li-\ncense checks, this stage involves drafting and bilateral signing'
 'laws. Following delineates how the framework facilitates li-\ncense renewal checks and renewals.\n1) License Renewal Check: The framework supports three\ntypes of license renewal checks (LRCs): license-driven,\ndataset-driven, and model-driven.\nIn license-driven LRC, AOs or COs conduct a periodic\nscan of the license registry, performing checkLicenseValidity\non each license. If a license fails the validity check, an AO\ncan execute the getModelsByLicense operation to gather the\nidentifiers of datasets and models that depend on the invalid\nlicense. These can be added to a blacklist to prevent the use\nof those datasets and models in future training of new models\nor retaining. The specifics of how the blacklist is stored and\nmanaged fall beyond the scope of this paper.\nDataset-driven and model-driven LRC can be conducted on-\ndemand before training a new model. In dataset-driven LRC,\nan AO can execute getDatasetLicense operation followed by'
 'to determine the license validity. The time complexity of\nthe LVC contract is directly proportional to the number ofenvironment variables that need validation. We abstract this\ntime complexity as O(|E|), where Eis the set of environment\nvariables to validate. Therefore, the overall time complexity is\nO(1) + O(|E|) =O(|E|).\nObtain licensed datasets. ThegetLicensedDatasets operation\nretrieves the list of dataset identifiers datasetId s each with\na valid license. It entails executing getDatasetLicense and\ncheckLicenseV alidity operations for each dataset. Given D\ndatasets, the overall time complexity is O(|D| × {O(1) +\nO(E)}=O(|D||E|).\nObtain authorized datasets by license. Given a license iden-\ntifier licenseId , the getDatasetsByLicense operation retrieves\ndatasets covered by the license. This operation performs a\nsearch of the DMR using the licenseId, resulting in a time\ncomplexity of O(1).\nObtain authorized models by license. Given a license iden-']","The license registry determines dataset eligibility for model training by checking the validity of the license using the LVC smart contract. Only datasets that pass the license check are considered eligible. In the case of public domain data, a preloaded public domain license in the registry always passes the LVC check. The LVC mechanism can vary based on the type of license, with some licenses having geographic restrictions, time limits, or usage limits. The framework allows for the creation of different LVC smart contracts to handle diverse and complex conditions, with a generic LVC interface contract dynamically selecting the specific LVC contract based on the license being evaluated.",0.10810810810810811,0.99999999998,1.0,1.0,0.9430381497276361
How have recent works in adaptation networks addressed computational costs by exploring alternative backbones and learning transformations?,"[1] F. Perez, J. Lopez, and H. Arguello, ""Privacy-Preserving Deep Learning Using Deformable Operators for Secure Task Learning,"" *IEEE Transactions on Neural Networks and Learning Systems*, Apr. 2024.

Recent works in adaptation networks have addressed computational costs by exploring alternative backbones and learning transformations. Some works have utilized different backbones like convMixer or vision transformers for the adaptation network [1]. These methods aim to explore alternative network architectures while also addressing the fundamental issue of additional computational costs.

References:
[1] F. Perez, J. Lopez, and H. Arguello, ""Privacy-Preserving Deep Learning Using Deformable Operators for Secure Task Learning,"" *IEEE Transactions on Neural Networks and Learning Systems*, Apr. 2024.","['nificant computational overhead. Other works have utilized\ndifferent backbones like convMixer [8] or vision transform-\ners [9] for the adaptation network. However, while these\nmethods explore alternative network architectures, they need\nto address the fundamental issue of additional computational\ncosts sufficiently. Furthermore, other methods learn the trans-\nformation instead of making it explicit by using Autoencoders\n[10] or GANs [11] to generate images very different from the\noriginal.\nMoving beyond these techniques, another line of work\nwithin PT is to design optics and algorithms for learning\nthe ad hoc transformation [12]. For example, recent works\nhave proposed designing a refractive camera lens to generate\nblurred images while extracting the most valuable features\nfor the task through end-to-end optimization [13]. This ap-\nproach solves the problem of capturing the original image\nand the computational cost but highlights the issue of the'
 'crypted data transformations and flexible neural network de-\nsigns for specific tasks.'
 'However, they often suffer from reduced task performance\nand high computational costs. To address these challenges,\nwe propose a novel Privacy-Preserving framework that uses\na set of deformable operators for secure task learning. Our\nmethod involves shuffling pixels during the analog-to-digital\nconversion process to generate visually protected data. Those\nare then fed into a well-known network enhanced with de-\nformable operators. Using our approach, users can achieve\nequivalent performance to original images without additional\ntraining using a secret key. Moreover, our method enables ac-\ncess control against unauthorized users. Experimental results\ndemonstrate the efficacy of our approach, showcasing its po-\ntential in cloud-based scenarios and privacy-sensitive applica-\ntions.\nIndex Terms —Computational Imaging, Deformable Op-\nerators, Image Privacy, Image Encryption\n1. INTRODUCTION\nAs deep neural networks continue to be deployed in real-'
 'Fig. 1 . Proposed framework for flexible feature learning from private images. The camera captures an image, which is then\npassed through a custom analog-to-digital converter to apply a transformation. The resulting measurement is a private image\nthat is an input to the flexible feature learning module. This module generates underlying features that can be used in any task\nsuch as classification, object detection, and segmentation.\ninference with this model. They can eliminate the privacy-\nutility trade-off, but the approach must still fully resolve the\nproblem, as Key-Nets only allow using pre-trained networks\ncontaining linear or ReLU layers. Moreover, they add com-\nplexity by requiring custom optical components. In general,\nexisting perceptual transformation techniques face limita-\ntions in balancing privacy-utility and computational costs,\nwhich restricts their application in real-world systems. Then,\novercoming this problem remains an open challenge. There-'
 'Securityand Privacy (EuroS&P) . IEEE,286–302.\n[29]Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and\nBlaise Aguera y Arcas. 2017. Communication-eﬃcient learning of deep net-\nworks from decentralized data. In Artiﬁcial Intelligence and Statistics . PMLR,\n1273–1282.[30] Arup Mondal,Yash More, RuthuHulikal Rooparaghunath, and Debayan Gupta.\n2021. Poster:Flatee:Federatedlearningacrosstrustedexecutionenvironments.In\n2021IEEEEuropeanSymposiumonSecurityandPrivacy(EuroS&P) .IEEE,707–709.\n[31]DianwenNg,XiangLan,MelissaMin-SzuYao,WingPChan,andMenglingFeng.\n2021. Federatedlearning:acollaborativeeﬀorttoachievebettermedicalimaging\nmodelsforindividualsitesthathavesmalllabelleddatasets. QuantitativeImaging\ninMedicine and Surgery 11,2 (2021), 852.\n[32]ThienDucNguyen,PhillipRieger,HuiliChen,HosseinYalame,HelenMöller-\ning, Hossein Fereidooni, Samuel Marchal, Markus Miettinen, Azalia Mirhoseini,\nShazaZeitouni,etal .2021. FLAME:TamingBackdoorsinFederatedLearning.']","Recent works in adaptation networks have addressed computational costs by exploring alternative backbones like convMixer or vision transformers for the adaptation network. Additionally, some methods learn the transformation explicitly using Autoencoders or GANs to generate images different from the original, while others design optics and algorithms for learning the ad hoc transformation, such as using a refractive camera lens to generate blurred images and extract valuable features through end-to-end optimization.",0.02127659574468085,0.99999999998,1.0,1.0,0.7703042251596296
How does the proposed framework ensure privacy protection and superior performance in deep learning tasks?,"Our proposed framework ensures privacy protection and superior performance in deep learning tasks by utilizing deformable operators to enable secure task learning on private images. The framework involves secret pixel shuffling parametrized by a key during image acquisition, followed by processing the transformed images using CNNs enhanced with deformable operators configured with the key. Extensive experiments on classification and segmentation tasks have validated that our technique offers robust privacy protection, eliminates the privacy-utility tradeoff, reduces computational costs, and outperforms existing methods while being more parameter-efficient [1].

References:
[1] F. Perez, J. Lopez, and H. Arguello, ""Privacy-Preserving Deep Learning Using Deformable Operators for Secure Task Learning,"" *IEEE Transactions on Neural Networks and Learning Systems*, Apr. 2024.","['applicability of our framework beyond just classification.\n4. CONCLUSION\nThis work introduced a novel privacy-preserving deep learn-\ning approach using deformable operators to enable secure task\nlearning on private images. Our essential contribution is a\nframework that applies secret pixel shuffling parametrized by\na key during image acquisition; the transformed images are\nthen processed by CNNs enhanced with deformable opera-\ntors configured with the key. Through extensive experiments\non classification and segmentation tasks, we validated that\nour technique provides robust privacy protection and elimi-\nnates the inherent privacy-utility tradeoff and computational\ncosts of prior works. Furthermore, our method avoids cum-\nbersome additions like adaptation networks. Moreover, our\napproach overcomes state-of-the-art performance while being\nmore parameter-efficient. Our framework provides a founda-\ntion for future research, such as developing customized en-'
 'world applications, mainly as software-as-a-service tools\nused through cloud computing platforms, users routinely up-\nload their sensitive data. For instance, medical records or\nimages containing private information to third-party servers,\nto mention a few. However, this exposes users to potentially\nserious privacy risks through unauthorized data access or in-\nformation leakage [1, 2]. Since users have little control over\nhow their information is used once uploaded. Thus, this lack\nof control raises significant privacy and security concerns.\nConsequently, it demands privacy-preserving deep learning\ntechniques to ensure reliable and secure systems, as urged\nincreasingly in the industry.\nTo address these privacy and security issues, various\napproaches have been proposed to protect sensitive data in\ncode is available at: https://github.com/Factral/PrivDLdeep learning systems. These approaches can be broadly\ncategorized into two main frameworks: fully homomorphic'
 'authorized user achieve full utility on the private data. Over-\nall, these comprehensive experiments validate the efficacy of\nour proposed framework to deliver strong privacy protection\nwith minimal impact on task performance for sensitive deep\nlearning applications.\nOnce we demonstrated the efficacy of our proposed\nmethod under the outlined settings, we evaluated our per-\nformance of the proposed approach using a PreResNet-110\n[18] adapted to our method compared to state-of-the-art tech-\nniques for private image classification.\nAs presented in Table 2 our method achieves better state-\nof-the-art accuracy on private image classification while be-\ning highly parameter efficient. Compared to methods like LE\nand ELE that rely on large models like Shakedrop with over\n29 million parameters, primarily due to the need for additional\nadaptation networks, our approach utilizing a PreResNet-110\narchitecture attains better accuracy (95.06%) with over 17x'
 '© 2024 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including\nreprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or\nreuse of any copyrighted component of this work in other works.\nPRIVACY-PRESERVING DEEP LEARNING USING DEFORMABLE OPERATORS FOR\nSECURE TASK LEARNING\nFabian Perez Jhon Lopez Henry Arguello\nDepartment of Computer Science, Universidad Industrial de Santander\nBucaramanga, 680002, Colombia\nABSTRACT\nIn the era of cloud computing and data-driven applica-\ntions, it is crucial to protect sensitive information to maintain\ndata privacy, ensuring truly reliable systems. As a result, pre-\nserving privacy in deep learning systems has become a critical\nconcern. Existing methods for privacy preservation rely on\nimage encryption or perceptual transformation approaches.'
 'are of dimension 3×224×244.\nIV. P ROPOSED SOLUTION FRAMEWORK\nThe framework of our solution is shown in Fig. 1. The\nsteps for performing private inference using our solution are\nas follows:\n1)The user aims to utilize resources in an untrusted cloud\nfor running their model and performing model inference\non input data, all while ensuring the privacy of both the\nmodel and the data.\n2)The model and data are decrypted within the secure\nand private TEE which is hosted on the cloud. The\ninformation within the TEE cannot be exposed to the\nuntrusted cloud environment.\n3)The model is split into critical and non-critical partitions\nwithin the TEE, based on the architecture of the CNN\nmodel and the optimal partitioning point.\n4)The execution of the critical model partition on the input\ndata is performed within the secure TEE.\n5)The output of the critical model partition which is\nsaved and sent out into the untrusted cloud for further\nprocessing.']","The proposed framework ensures privacy protection and superior performance in deep learning tasks by applying secret pixel shuffling parametrized by a key during image acquisition, processing the transformed images with CNNs enhanced with deformable operators configured with the key. Extensive experiments on classification and segmentation tasks validated that the technique provides robust privacy protection, eliminates the privacy-utility tradeoff and computational costs of prior works, avoids cumbersome additions like adaptation networks, and overcomes state-of-the-art performance while being more parameter-efficient.",0.0380952380952381,0.99999999998,1.0,1.0,0.9708114826406288
What is the time complexity of the DMR hash map operation for datasetId as key and licenseId presence in DMR record?,"The time complexity of the DMR hash map operation for datasetId as the key and licenseId presence in the DMR record is O(1) [1]. This means that the operation has a constant time complexity, regardless of the size of the dataset or the number of licenses involved.

References:
[1] Y. Sai, Q. Wang, G. Yu, H.M.N. Bandara, and S. Chen, ""Is Your AI Truly Yours? Leveraging Blockchain for Copyrights, Provenance, and Lineage,"" *IEEE Transactions on Smart Grid*, Mar. 2024.","['the DMR hash map using\nthe dataset datasetId as\nthe key, which incurs a\ntime complexity of O(1).\nDepending on whether the\nreturned DMR record contains\nalisenceId , this operation either retrieves the license by\nlicenseId or searches for a relevant license in the license\nregistry as follows:\n6'
 '•Retrieve the license with licenseId : This operation queries\nthe license registry hash map using the licenseId as the\nkey. As the resulting time complexity is O(1), the overall\ntime complexity remains the same.\n•Search for a relevant license : This operation extracts the\ndataset’s copyrightOwnerId and performs a search on the\nlicense registry using copyrightOwnerId , which involves\na complexity of O(1). This search may yield a list of\nlicenses with the same copyrightOwnerId (albeit with\ndifferent scopes). Finally, a scan is conducted on the list\nof licenses to filter out the licenses with irrelevant scopes.\nOur framework operates on the premise that license\nscopes do not intersect, ensuring each dataset corresponds\nto at most one license. As CO is unlikely to have many\nlicenses with the same AO for practical reasons, one can\nassume the size of this list to be small. Consequently, we\ncan still assume the overall time complexity to be O(1).'
 'of edges. Therefore, given a graph with a set of Mmodels\nandDdatasets, the time complexity of the graph traversal is\nO(|D|+|M|). As getDatasetLicense ’s complexity is O(1),\nthe graph traversal dominates the overall time complexity.\nCheck license validity. Given license data and environment\nvariables as transaction inputs, the checkLicenseValidity oper-\nation verifies the validity of the license. Environment variables\ninclude the current date, the operating locations of AOs, and\nother variables that could potentially contravene the terms and\nconditions stipulated in the license agreement.\nFirst, we need to locate the corresponding LVC smart\ncontract for validating the license. This can be accomplished\nusing another hash map where the license type typeID serves\nas the key and LVC’s address as the value. Consequently,\nthis lookup operation can be performed in constant time, i.e.,\nO(1). Next, we need to invoke the identified LVC contract'
 'to determine the license validity. The time complexity of\nthe LVC contract is directly proportional to the number ofenvironment variables that need validation. We abstract this\ntime complexity as O(|E|), where Eis the set of environment\nvariables to validate. Therefore, the overall time complexity is\nO(1) + O(|E|) =O(|E|).\nObtain licensed datasets. ThegetLicensedDatasets operation\nretrieves the list of dataset identifiers datasetId s each with\na valid license. It entails executing getDatasetLicense and\ncheckLicenseV alidity operations for each dataset. Given D\ndatasets, the overall time complexity is O(|D| × {O(1) +\nO(E)}=O(|D||E|).\nObtain authorized datasets by license. Given a license iden-\ntifier licenseId , the getDatasetsByLicense operation retrieves\ndatasets covered by the license. This operation performs a\nsearch of the DMR using the licenseId, resulting in a time\ncomplexity of O(1).\nObtain authorized models by license. Given a license iden-'
 'subsequently retrained with a fourth dataset to yield Model-2.\nThe two models are linked through Model-2’s sourceModelId\nattribute and Model-1’s childModelList . A dataset and a model\nare linked through the model’s datasetList and the dataset’s\nmodelList . A license and a dataset are linked through the\nlicense’s datasetList and the dataset’s licenseId .\nB. Functional Operations\nThis section delineates the operations that can be performed\nby AOs and COs, along with their time complexity analysis.\nTable II lists the time complexity of operations and the entities\nauthorized to perform them. We assume that the on-chain\nlicense registry, DMR, and MMR are implemented as hash\nmaps on a smart contract, resulting in a time complexity of\nO(1)for searching them.\nFig. 6: Model, dataset, and\nlicense relationships.Obtain dataset licenses. The\ngetDatasetLicense operation\nretrieves copyright license of\na given a dataset identifier\ndatasetId . It initially searches\nthe DMR hash map using']",O(1),0.17757009345794392,0.8874999999778125,1.0,1.0,0.9980853276999225
How do cluster-based techniques and anomaly detection help prevent sleep deprivation attacks in IoT devices due to vulnerabilities from fragmentation and replay attacks?,"Cluster-based techniques and anomaly detection play a crucial role in preventing sleep deprivation attacks in IoT devices due to vulnerabilities from fragmentation and replay attacks. These techniques offer a potential solution to deplete devices' energy by identifying abnormal behavior and patterns within the network. By utilizing cluster-based techniques, IoT devices can be grouped based on similarities, allowing for more efficient monitoring and detection of anomalies that could indicate a potential attack [1].

Moreover, anomaly detection algorithms can analyze network traffic and device behavior to identify deviations from normal patterns, which can help in detecting and preventing sleep deprivation attacks. By continuously monitoring the network for unusual activities, anomaly detection systems can raise alerts and take preventive actions to mitigate the risks posed by vulnerabilities from fragmentation and replay attacks [2].

References:
[1] J. Cecílio, A. Oliveira de Sá, and A. Souto, ""Software-based Security Framework for Edge and Mobile IoT,"" *IEEE Transactions on Mobile Computing*, Apr. 2024.
[2] Bhattasali and Chaki, ""Sleep Deprivation Attacks in IoT Devices: A Cluster-based Approach,"" *IEEE International Conference on Communications*, Jun. 2011.","['Software-based Security Framework for Edge and Mobile IoT PREPRINT AEIC-2024\nInsecure physical interfaces also represent a considerable risk. Strategies for preventing physical tampering and secure\naccess service management are essential to mitigate these risks (Khatri et al. [2017]). For sleep deprivation attacks, which\naim to deplete devices’ energy, cluster-based techniques and anomaly detection offer a potential solution (Bhattasali and\nChaki [2011]). Fragmentation in IoT devices creates additional vulnerabilities, where replay attacks can be particularly\ndamaging. Content chaining schemes and split buffer approaches are presented as viable solutions (But [2013]). Within\nthe scope of IoT attacks, there is a need for a deeper analysis of middleware security. Robust authentication, access\ncontrol, and secure protocols like HTTPS and XMPP are proposed measures to bolster security at this layer (Conzon\net al. [2012]).'
 '•Data Tampering: Attackers try to manipulate or tamper with data during communication. The proposed\narchitecture uses lightweight encryption standards following NIST guidelines for data encryption and integrity.\n•Physical Tampering: Physical access to IoT devices for tampering or unauthorized manipulation. Secure\naccess service management and regular code integrity verification are applied.\n•Jamming and Adversarial Attacks: Deliberate disruptions to wireless communication to compromise IoT\ndevices. Signal strength analysis and packet delivery rate verification are used to detect and counter jamming\nand adversarial attacks.\n•Replay Attacks: Replay attacks exploiting fragmentation vulnerabilities in IoT devices. Challenge approach,\ndata integrity, and application integrity verifications are used to prevent and detect replay attacks.\nConsidering this threat model, the following assumptions are made:'
 'of vulnerabilities in IoT devices, leading to a large range of attack techniques that compromise data integrity and\nconfidentiality, significantly threatening IoT systems’ functionality and security.\nOne of the primary challenges in the IoT landscape is balancing the affordability of devices with implementation of\nrobust security measures. For instance, jamming and adversarial attacks, which aim to disrupt wireless communication,\nare particularly disruptive in resource-limited devices (Dong et al. [2013]). Measures such as signal strength analysis\nand packet delivery rate verification have been proposed as effective solutions to detect such activities (Xu et al. [2005]).\nAdditionally, the insecure setup of IoT devices exposes them to various vulnerabilities. Researchers have suggested\nintroducing artificial noise and robust authentication processes to secure devices during this critical phase (Chae et al.'
 'remote servers and embedded IoT devices to balance security robustness and energy efficiency.\nThe proposed approach uses lightweight cryptography, optimizing device performance and security\nwithout overburdening their limited resources. Our architecture stands out for integrating Edge\nservers and a central Name Server, allowing secure and decentralized authentication and efficient\nconnection transitions between different Edge servers. This architecture enhances the scalability of\nthe IoT network and reduces the load on each server, distributing the responsibility for authentication\nand key management.\nKeywords: IoT Security, Edge, Device Protection, Data reliability.\n1 Introduction\nGiven the increasing ubiquity of Internet of Things (IoT) devices in our daily lives, understanding the variety and\ncomplexity of cyberattacks these devices face has become imperative. In Johnston [2019], highlights a broad spectrum'
 'Software-based Security Framework for Edge and Mobile IoT PREPRINT AEIC-2024\nprinciples, our proposed architecture sets the stage for a more secure, scalable, and energy-efficient future for the\nMobile Internet of Things (MIoT).\nAcknowledgments\nThis work was supported by the LASIGE Research Unit (ref. UIDB/00408/2020 and ref. UIDP/00408/2020).\nReferences\nNick Johnston. A gentle introduction and an exploration of root causes,\n2019. URL https://owasp.org/www-chapter-toronto/assets/slides/\n2019-12-11-OWASP-IoT-Top-10---Introduction-and-Root-Causes .\nQi Dong, Donggang Liu, and Matthew Wright. Mitigating jamming attacks in wireless broadcast systems. Wireless\nnetworks , 19:1867–1880, 2013.\nWenyuan Xu, Wade Trappe, Yanyong Zhang, and Timothy Wood. The feasibility of launching and detecting jamming\nattacks in wireless networks, 2005.\nSeong Ho Chae, Wan Choi, Jung Hoon Lee, and Tony Q.S. Quek. Enhanced secrecy in stochastic wireless networks:']",Cluster-based techniques and anomaly detection help prevent sleep deprivation attacks in IoT devices by offering a potential solution to deplete devices' energy. Fragmentation in IoT devices creates vulnerabilities where replay attacks can be damaging. Content chaining schemes and split buffer approaches are presented as viable solutions to address these vulnerabilities.,0.04,0.999999999975,1.0,0.8571428571428571,0.9713624275008758
