question,answer,contexts,ground_truth,context_relevancy,context_precision,context_recall,faithfulness,answer_relevancy
How can information professionals adapt the approach to user-centered design from the literature of HCI for the design of user-centered information systems?,"According to Schulze [1], information professionals can adapt the approach to user-centered design from the literature of HCI for the design of user-centered information systems by drawing from a more interdisciplinary perspective on user-centered design. The paper outlines an approach from the literature of HCI that can be readily adapted by information professionals for the design of user-centered information systems.

References:
[1] A. A. N. Schulze, ""User-Centered Design for Information Professionals,"" *Journal of Education for Library and Information Science*, vol. 42, no. 2, pp. 116-122, Spring 2001.","['depends greatly on the discipline, back- \n ground, and research interests of its pro-  ponents. This paper introduces the con- \n cept of user-centered design and its \n broad range of meanings across disci- \n plines. It suggests ways in which infor- \n mation professionals can draw from a \n more interdisciplinary perspective on \n user-centered design. Finally, it outlines \n an approach to user-centered design \n from the literature of HCI that can be \n readily adapted by information profes- \n sionals for the design of user-centered \n information systems. \n User-Centered Design \n There are many fields and subfields that \n interact in the design and implementa- \n tion of information systems: information \n retrieval, information needs and uses, \n HCI, and systems engineering are just a \n few. In these and many other fields the \n concept of user-centered design is \n endowed with a diverse range of both \n 1 1 6 Volume 42, Number 2 \nThis content downloaded from'
 '/A\n User-Centered Design for \n Information Professionals \n Anna Nookes Schulze \n Most information professionals would agree that user-centered design makes an \n important contribution to high quality information systems. However, there is no gen- \n eral agreement about how to define the term ""user-centered design,"" or how best to \n implement user-centered design strategies in the development of systems and servic- \n es. This paper describes a wide range of meanings associated with user-centered \n design in information studies and in other cognate disciplines, and argues for a more \n coherent and widely accepted definition. It proposes that a general definition of user- \n centered design drawn from the literature of human-computer interaction (HCI) could \n serve as a basic framework for system design and support interdisciplinary work. It \n also describes some useful methods of implementing this framework in the develop- \n ment of user-centered information systems.'
 ""User-Centered Design for Information Professionals 1 1 9 \n long tradition of strength in the areas of \n document representation, organization \n of information, information needs, and \n information-seeking behavior. Regarding \n the latter, they have dissected users' \n search strategies, examined patterns of \n query formation, and modeled their cog- \n nitive states in the process of informa- \n tion seeking.14 All of these strengths can \n contribute to good design of information \n systems. However, what has often been \n lacking in the resulting information sys- \n tems is good usability. In his influential \n book, Usability Engineering, Nielsen \n defines system usability as multifaceted \n and comprising the following: \n ■ learnability: the extent to which the \n system is easy for the user to learn; \n ■ efficiency: the extent to which the \n system is efficient to use, enabling \n high productivity; \n ■ memorability: the extent to which""
 'achieve (such as, ""80 percent of users \n must be able to formulate their query in \n the first twenty seconds at the inter- \n face"") then the process is referred to as \n usability engineering.21 \n Conclusion \n The professional and scholarly horizons \n of information professionals are expand- \n ing profoundly at this time. With an \n increasing emphasis on interdiscipli- \n nary work, researchers will need to bor- \n row or adapt the best ideas from diverse \n cognate disciplines. Educators will need \n to ensure that a deep-rooted knowledge \n of user needs and user-centered design \n principles is an integral part of the \n design of information systems in the \n classroom.22 Practitioners must continue \n to develop and hone their professional \n skills in user-needs assessment, inter- \n face design, project management, and \n evaluation methods. All information \n professionals will need to work toward \n an integrated, interdisciplinary theory of'
 ""system. A good interface directs the \n user's attention to important informa- \n tion, makes it obvious what a user needs \n to do, and provides help and guidance \n throughout the information-seeking \n process. If the interface fails to accom- \n plish these objectives, the user may per- \n ceive the overall system as a failure - no \n matter how well its functionality was \n designed. What information profession- \n als can, and should, do is draw relevant \n knowledge from cognate disciplines \n such as HCI so as to enhance their abili- \n ty to provide useful, efficient, and time- \n ly access to information. This cognate \n knowledge can be used to develop a \n more holistic approach to user-centered \n design that balances the demands of sys- \n tem form and function. \n University of Michigan researchers \n Gary and Judy Olson have defined user- \n centered design in a way that embodies \n the meaning and spirit of Belkin's defi- \n nition of interdisciplinarity while pro-""]",Information professionals can adapt the approach to user-centered design from the literature of HCI by drawing from a more interdisciplinary perspective on user-centered design. This involves understanding the broad range of meanings of user-centered design across disciplines and implementing an approach that can be readily adapted for the design of user-centered information systems.,,0.007692307692307693,0.8874999999778125,1.0,1.0
How does gender affect how group members perceive women and men in leadership positions?,"Gender affects how group members perceive women and men in leadership positions. Research by Ridgeway (2001) indicates that people tend to rate the performance of groups led by women lower compared to those led by men. However, these gender differences can be overcome when the role of women as leaders is institutionalized (Lucas, 2003) [1].

References:
[1] C. L. Ridgeway, ""Gender, status, and leadership,"" *Journal of Social Issues*, vol. 57, pp. 637-655, 2001.
[2] J. W. Lucas, ""Status processes and the institutionalization of women as leaders,"" *American Sociological Review*, vol. 68, pp. 464-480, 2003.","['Weitzel-O’Neill, 1977 ). Experimental studies on double standards\nshow that participants will give higher ratings for the same perfor-\nmance of a man than a woman ( Foschi, 1996 ). These gender differ-\nences affect how people assess their own competency and, in turn,\nformulate their own performance goals ( Correll, 2004 ). Gender also\naffects how group members perceive women and men in leader-\nship positions ( Ridgeway, 2001 ). Studies show that people rate\nthe performance of groups led by women as lower compared to\nthose with leaders who are men ( Lucas & Lovaglia, 1998 ). However,\nthese groups have the capacity to overcome these gender differ-\nences when they institutionalize the role of women as leaders\n(Lucas, 2003 ).\n2.2. Gender and user perceptions of computers\nThere have been decades of research investigating the effects of\ngender on individual perceptions of using computer technology\n(Compton, Burkette, & Burkett, 2002; Havelka, 2003; Huffman,'
 'Quarterly, 52 , 197–206 .\nRidgeway, C. L. (2001). Gender, status, and leadership. Journal of Social Issues, 57 ,\n637–655 .194 M.N. Posard / Computers in Human Behavior 37 (2014) 189–195'
 'Huffman, A. H., Whetten, J., & Huffman, W. H. (2013). Using technology in higher\neducation: The inﬂuence of gender roles on technology self-efﬁcacy. Computers\nin Human Behavior, 29 , 1779–1786 .\nImhof, M., Vollmeyer, R., & Beierlein, C. (2007). Computer use and the gender gap:\nThe issue of access, use, motivation, and performance. Computers in Human\nBehavior, 23 , 2823–2837 .\nLovaglia, M. J., & Houser, J. A. (1996). Emotional reactions and status in groups.\nAmerican Sociological Review, 61 , 867–883 .\nLucas, J. W. (2003). Status processes and the institutionalization of women as\nleaders. American Sociological Review, 68 , 464–480 .\nLucas, J. W., & Lovaglia, M. J. (1998). Leadership status, gender, group size, and\nemotion in face-to-face groups. Sociological Perspectives, 41 , 617–637 .\nMarkoff, J. (2011). Computer wins on ‘Jeopardy!’: Trivial, it’s not.’’ New York Times .\n(Accessed 8.12.13). < http://www.nytimes.com/2011/02/17/science/\n17jeopardy-watson.html?pagewanted=all&_r=0 >.'
 'expectations and behavior. In J. Berger & M. Zelditch, Jr. (Eds.), Status, power and\nlegitimacy (pp. 155–174). New Brunswick, NJ: Transaction Publishers .\nBrezina, T., & Winder, K. (2003). Economic disadvantage, status generalization, and\nnegative racial stereotyping by white Americans. Social Psychology Quarterly, 66 ,\n402–418 .\nCech, E. A. (2013). Ideological wage inequalities? The technical/social dualism and\nthe gender wage gap in engineering. Social Forces, 91 , 1147–1182 .\nCompton, D. M., Burkette, W. H., & Burkett, G. G. (2002). No sex difference in\nperceived competence of computer use among male and female college\nstudents in 2002. Psychological Reports, 92 , 503–511 .\nCorrell, S. J. (2004). Constraints into preferences: Gender, status, and emerging\ncareer aspirations. American Sociological Review, 69 , 93–113 .\nEagly, A. H., & Karau, S. J. (2002). Role congruity theory of prejudice toward female\nleaders. Psychological review, 109 , 573–598 .'
 '17jeopardy-watson.html?pagewanted=all&_r=0 >.\nMeeker, B. F., & Weitzel-O’Neill, P. A. (1977). Sex roles and interpersonal behavior in\ntask-oriented groups. American Sociological Review, 42 , 91–105 .\nNass, C., & Moon, Y. (2000). Machines and mindlessness: Social responses to\ncomputers. Journal of Social Issues, 56 , 81–103 .\nNass, C., Moon, Y., & Green, N. (1997). Are machines gender neutral? Gender-\nstereotypic responses to computers with voices. Journal of Applied Social\nPsychology, 27 , 864–876 .\nOng, C. S., & Lai, J. Y. (2006). Gender differences in perceptions and relationships\namong dominants of e-learning acceptance. Computers in Human Behavior,\n22(5), 816–829 .\nPetersen, T., & Morgan, L. A. (1995). Separate and unequal: Occupation-\nestablishment sex segregation and the gender wage gap. American Journal of\nSociology, 101 , 329–365 .\nRiches, P., & Foddy, M. (1989). Ethnic accent as a status cue. Social Psychology\nQuarterly, 52 , 197–206 .']","Gender affects how group members perceive women and men in leadership positions. Studies show that people rate the performance of groups led by women as lower compared to those with leaders who are men. However, these groups have the capacity to overcome these gender differences when they institutionalize the role of women as leaders.",0.9277715174769522,0.03571428571428571,0.8041666666465626,1.0,1.0
What are the key components of system usability in User-Centered Design according to Nielsen's definition in Usability Engineering?,"According to Nielsen's definition in Usability Engineering, the key components of system usability in User-Centered Design are as follows: 

- Learnability: the ease with which users can learn to use the system.
- Efficiency: how efficiently users can accomplish tasks with the system, leading to high productivity.
- Memorability: the system's ease of remembering how to use it after a period of not using it.
- Errors: the system's ability to have a low error rate, recover from errors, and avoid catastrophic errors.
- Satisfaction: the system's pleasantness to use, contributing to user satisfaction [1].

References:
[1] A. A. N. Schulze, ""User-Centered Design for Information Professionals,"" *Journal of Education for Library and Information Science*, vol. 42, no. 2, pp. 116-122, Spring 2001.","[""User-Centered Design for Information Professionals 1 1 9 \n long tradition of strength in the areas of \n document representation, organization \n of information, information needs, and \n information-seeking behavior. Regarding \n the latter, they have dissected users' \n search strategies, examined patterns of \n query formation, and modeled their cog- \n nitive states in the process of informa- \n tion seeking.14 All of these strengths can \n contribute to good design of information \n systems. However, what has often been \n lacking in the resulting information sys- \n tems is good usability. In his influential \n book, Usability Engineering, Nielsen \n defines system usability as multifaceted \n and comprising the following: \n ■ learnability: the extent to which the \n system is easy for the user to learn; \n ■ efficiency: the extent to which the \n system is efficient to use, enabling \n high productivity; \n ■ memorability: the extent to which""
 '9. B. Shackel, ""Usability- Content, Frame- \n work, Definition, Design and Evaluation,"" \n in Human Factors for Informatics \n Usability, B. Shackel, ed. (New York: \n Cambridge Univ. Pr., 1995), 31. \n 10. J. Karat, ""Evolving the Scope of User- \n centered Design,"" Communications of \n the ACM 40, no. 7 (July 1997): 38. \n 11. J. D. Gould, ""How to Design Usable \n Systems,"" in Handbook of Human- \n Computer Interaction, M. Helander, ed., \n (New York: North-Holland, 1988); J. \n Whiteside, J. Bennett, and K. Holtzblatt, \n ""Usability Engineering: Our Experience \n and Evolution,"" in Handbook of Human- \n Computer Interaction, M. Helander, ed. \n (New York: North-Holland, 1988), \n 791-817. \n 12. J. D. Gould, ""How to Design Usable \n Systems,"" in Handbook of Human- \n Computer Interaction, M. Helander, ed.  (New York: North-Holland, 1988). \n 13. N. Belkin, Panel presentation on inter- \n disciplinary research, 1999 ALISE An- \n nual Conference, Philadelphia, Pa.,'
 'User-Centered Design for Information Professionals 1 21 \n al or intended users have been identi- \n fied, they can begin to participate in the \n design process. Mock-ups, storyboards, \n and other kinds of simulations can be \n used to convey the look and feel of a sys- \n tem before a single line of code is writ- \n ten. This allows users to identify \n possible problems and deficiencies that \n would be very costly to correct once the \n designers have committed to a fully \n functional system and interface. These \n methods help to support cycles of rapid \n prototyping and feedback in which the \n design concept is incrementally refined. \n Usability testing provides invaluable \n input in the latter stages of the design \n process. This method involves user test- \n ing of the system under realistic condi- \n tions and with typical user tasks.20 \n Where usability testing includes per- \n formance metrics that the system must \n achieve (such as, ""80 percent of users'
 ""■ memorability: the extent to which \n the system is easy to remember, so  that the user doesn't have to relearn \n it after a lapse in use; \n ■ errors: the extent to which the sys- \n tem has a low error rate in general, is \n free of catastrophic error, and facili- \n tates recovery from user error; and  ■ satisfaction: the extent to which the \n system is pleasant to use.15 \n For most users, an information sys- \n tem that has good usability will allow \n for a quick assessment of what the sys- \n tem offers and how it works. The user \n should be able to determine what needs \n to be done in order to obtain the needed \n information in a reasonable amount of \n time and without much duress. \n The poor usability of many informa- \n tion systems may be due to an approach \n to the design of information systems that \n emphasizes function (system features) \n over form (interface design). Information \n professionals tend to focus attention pri- \n marily on designing the system func-""
 'Designers must understand who the \n users will be and what tasks they will \n do. This requires direct contact with \n users at their place of work. If possible, \n designers should learn to do some or all \n of the users\' tasks. Such studies of the \n user should take place before the system \n design work starts.9 \n Karat maintains that ""all techniques \n that involve users in design can be \n called user-centered design tech- \n niques.""10 However, what best defines \n the concept of user-centered design to \n his mind are two chapters in the \n Handbook of Human-Computer Inter- \n action by Gould, and by Whiteside, \n Bennett, and Holtzblatt, respectively.11 \n Gould\'s chapter describes four princi- \n ples for designing usable systems: \n ■ early focus on users and tasks, \n through direct and ongoing contact; \n ■ empirical measurement, i.e., testing \n against established nontrivial per-  formance measures;  ■ iterative design, in which succes- \n sive prototypes are tested and \n refined; and']","The key components of system usability in User-Centered Design according to Nielsen's definition in Usability Engineering are learnability, efficiency, and memorability.",0.9809051859472738,0.043478260869565216,0.6999999999766667,1.0,0.8571428571428571
"How does EMR quality improvement affect medical care with data scientists, physicians, and CDSS developers involved?","Improvement in Electronic Medical Record (EMR) quality has a significant impact on medical care when involving data scientists, physicians, and Clinical Decision Support System (CDSS) developers. Enhancing the quality of EMR not only provides data scientists with more valuable data for analysis but also increases their confidence in the results obtained from analyzing EMR data [1]. Additionally, the improvement in human-computer interaction within EMR is crucial for physicians to understand the importance of such systems in their daily practice and the utilization of data stored within these systems [1].

Physicians, data scientists, and CDSS developers collaborate closely to address the needs and challenges in EMR systems. Ethnographic interviews with physicians are conducted to comprehend their interactions with the system, similar to the approach taken with data scientists [1]. The DMAIC cycle is utilized to enhance the usability of the system under development, ensuring a comprehensive approach to improving EMR quality and usability [1].

References:
[1] E. V. Bologva, D. I. Prokusheva, A. V. Krikunova, N. E. Zvartaub, and S. V. Kovalchuka, ""Human-Computer Interaction in Electronic Medical Records: from the Perspectives of Physicians and Data Scientists,"" *Procedia Computer Science*, vol. 100, pp. 915-920, Oct. 2016.","['in EMR. It also stimulates the adoption of EMR by physicians. These changes should improve the quality of medical care. Good quality of EMR provides data scientists with more data useful for analysis and more confidence about the relevance of the results obtained from EMR data analysis. \nMeanwhile, as mentioned above, improvement of human-computer interaction in EMR demands not only \ntechnical solutions, but also facilitation of physicians’ understanding of the importance of such systems for their routine practice and further use of data stored in such systems. CDSS developers will work closely with physicians \nand data scientists to understand their needs and difficulties. Therefore, we will conduct ethnographic interviews \nwith physicians, like we did with data scientists, to understand the behavior and rituals of people interacting with the system . We plan to use DMAIC cycle to improve the usability of the system under development.  \nAcknowledgements'
 '3. Conclusion and Future Works \nCompleteness and accuracy of data in EMR forms the basis for substantial benefits, including better care and \ndecrease in healthcare costs. The important part of the EM R is the design of HCI. Improvement of human-computer \ninteraction affects far more processes than it might seem at the first glance. Keeping in mind that HCI affects \nphysician adoption of EMR, it also touches the course of  treatment, healthcare quality measurement, medical data \nanalysis, and many other aspects that are not covered in this paper. This is the reason why EMR systems should be designed, implemented, and used appropriately. Otherwise, medical systems will result in unintended adverse consequences, such as misdiagnosis, underestimation of disease severity of concomitant diseases or drug-drug interactions. All of this may affect patient safety. \nUsage of integrated CDSS aimed at improving HCI provides certain benefits and reduces the number of mistakes'
 '919  Ekaterina V . Bologva et al.  /  Procedia Computer Science   100  ( 2016 )  915 – 920 \n2.4. Physicians’ and Data Scientists’ Partic ipation in the Process of CDSS Development \nTo improve user interaction of the medical information system, we use the cycle DMAIC (Define, Measure, \nAnalyze, Improve and Control)28.Currently we have defined the problem an d iden tified possible causes according to \nthe first phase of the DMAIC cycle. The study was conducted in real contexts and provides rich qualitative data to \ndevelop the CDSS and the vision of the future system. In the cycle of Measure-Analyze-Improve, we will make a \nnew version of CDSS. Due to the fact that users invoke the MIS every day, we will apply a method of Subjective Mental Effort Question (SMEQ)\n29 for measuring satisfaction on every stage of cycle. A seven-digit scale of \nresponses provides a good balance between the number of options for making an effective choice by the respondent and exceptions error of measurement.'
 '13,14 and attempts to identify the critical success factors for CCDS systems have provided \nconflicting results13. CDSS takes the information from forms were filled in EMR and can provide inadequate advice \ndue to incomplete and unstructured EMR data15. \n2. Current Study \nThis paper presents an ongoing study aimed toward EMR quality assessment and improvement as a part of \ngeneral conceptual and technolog ical basis for CDSS building16. The considered issues appear and are resolved \nwithin a scope of optimization for decision making in me dicine and healthcare which uses EMR as a core source of \ninformation on patients’ curation in hospital. This makes the EMR quality improvement to be considered as an important problem for CDSS development. \n2.1. Episode Description \nFor effective work with data for both physician and data analyst, it is necessary to have full information about the'
 'interaction, that does not match with their mental models and do not meet the requirements of document flow10, 11. \nPoorly designed and cumbersome user interfaces of EMR input data can complicate the structured data-entry that will lead to a deterioration of data quality and incompleteness of data\n12. Consequently, this can lead to suboptimal \nfunctioning of information systems of medical technology, integrated into the EMR. An example of such technology is clinical decision support system (CDSS), which is one of the most effective strategies for improving clinical decisions \n12,13. CDSS often requires a large amount of data about the patient (demographic data, data on complaints, \nsymptoms, medical history, physical examination, laborator y and other tests). Despite the fact that the researches \naim were improving the quality of service, most of researches reported only about the improvement of the professional performance']","Good quality of EMR resulting from improvement efforts can provide data scientists with more useful data for analysis and increase their confidence in the relevance of the results obtained from EMR data analysis. In addition, the improvement of EMR quality stimulates the adoption of EMR by physicians, ultimately leading to better medical care.",0.9966562829774636,0.13846153846153847,0.99999999998,1.0,1.0
How do gender differences affect perceptions of women and men in leadership roles based on studies on double standards and user perceptions of computers?,"[1] Posard (2014) explores the impact of gender on user perceptions of computers. The study found that men and boys tend to feel more comfortable using computers compared to women and girls. Additionally, men reported higher levels of self-efficacy with new technology than women. Gender roles play a significant role in influencing self-perceptions and beliefs surrounding technology use. 

[2] Posard (2014) also delves into how gender affects the performance expectations that users have for computerized partners. The study revealed that users tend to expect better performance from a computerized partner personified as a man compared to one described as a woman. Users also rated computers with a man's voice more positively than those with a woman's voice on gender-stereotypical tasks. 

References:
[1] M. N. Posard, ""Status processes in human-computer interactions: Does gender matter?,"" *Computers in Human Behavior*, vol. 37, pp. 189-195, May 2014.","['Weitzel-O’Neill, 1977 ). Experimental studies on double standards\nshow that participants will give higher ratings for the same perfor-\nmance of a man than a woman ( Foschi, 1996 ). These gender differ-\nences affect how people assess their own competency and, in turn,\nformulate their own performance goals ( Correll, 2004 ). Gender also\naffects how group members perceive women and men in leader-\nship positions ( Ridgeway, 2001 ). Studies show that people rate\nthe performance of groups led by women as lower compared to\nthose with leaders who are men ( Lucas & Lovaglia, 1998 ). However,\nthese groups have the capacity to overcome these gender differ-\nences when they institutionalize the role of women as leaders\n(Lucas, 2003 ).\n2.2. Gender and user perceptions of computers\nThere have been decades of research investigating the effects of\ngender on individual perceptions of using computer technology\n(Compton, Burkette, & Burkett, 2002; Havelka, 2003; Huffman,'
 'Whetten, & Huffman, 2013; Imhof, Vollmeyer, & Beierlein, 2007;\nNass, Moon, & Green, 1997; Ong & Lai, 2006; Rosen & Maguire,\n1990 ). Some of these studies have found that men and boys feel\nmore comfortable with using computers than women and girls,\nwhile other research has found little to no gender difference\n(Whitley, 1997 ). In one recent study, Huffman et al. (2013)\nadministered a survey to college students that asked them about\nmasculine gender roles and their beliefs surrounding technology\nself-efﬁcacy. The results showed that men report higher levels of\nself-efﬁcacy with using new technology than women. This study\nalso found a similar effect from masculine gender roles that was\nindependent of participants’ gender ( Huffman et al., 2013 ).\nGender roles not only inﬂuence the self-perceptions of those\nwho use computer technology, it could also affect how users per-\nceive these machines. This is what Nass, Moon, and Green (1997)'
 'will affect the performance expectations that human users have\nfor this machine:\nHypothesis 1. People will expect a computerized partner that is\npersoniﬁed as a man to perform better on a gender-neutral task\nthan when this machine is described as being a woman.\nThere is some evidence from research on human and computer\ninteractions that people evaluate computers differently when they\nare personiﬁed as being a man or a woman ( Nass & Moon, 2000;\nNass et al., 1997 ).Nass and colleagues (1997) found that users\nrated a computer with a man’s voice more positively than a\nmachine using a woman’s voice on gender-stereotypical tasks.\nHypothesis 2 predicts a similar effect when people work in groups\nwith a computerized partner named James or Julie on a gender-\nneutral task:\nHypothesis 2. People will rate the performance of a computerized\npartner that is personiﬁed as a man higher on a gender-neutral\ntask than the same partner that is described as being a woman.'
 'Huffman, A. H., Whetten, J., & Huffman, W. H. (2013). Using technology in higher\neducation: The inﬂuence of gender roles on technology self-efﬁcacy. Computers\nin Human Behavior, 29 , 1779–1786 .\nImhof, M., Vollmeyer, R., & Beierlein, C. (2007). Computer use and the gender gap:\nThe issue of access, use, motivation, and performance. Computers in Human\nBehavior, 23 , 2823–2837 .\nLovaglia, M. J., & Houser, J. A. (1996). Emotional reactions and status in groups.\nAmerican Sociological Review, 61 , 867–883 .\nLucas, J. W. (2003). Status processes and the institutionalization of women as\nleaders. American Sociological Review, 68 , 464–480 .\nLucas, J. W., & Lovaglia, M. J. (1998). Leadership status, gender, group size, and\nemotion in face-to-face groups. Sociological Perspectives, 41 , 617–637 .\nMarkoff, J. (2011). Computer wins on ‘Jeopardy!’: Trivial, it’s not.’’ New York Times .\n(Accessed 8.12.13). < http://www.nytimes.com/2011/02/17/science/\n17jeopardy-watson.html?pagewanted=all&_r=0 >.'
 'leaders. Psychological review, 109 , 573–598 .\nFoschi, M. (1996). Double standards in the evaluation of men and women. Social\nPsychology Quarterly, 59 , 237–254 .\nGriggs, B. (2011). Why computer voices are mostly female. CNN. (Accessed\n31.03.13). < http://www.cnn.com/2011/10/21/tech/innovation/female-\ncomputer-voices/ >.\nHavelka, D. (2003). Predicting software self-efﬁcacy among business students: A\npreliminary assessment. Journal of Information Systems Education, 14 , 145–152 .\nHough, Andrew (2010). ‘‘Foxy ‘Roxxxy’: World’s ﬁrst ‘sex robot’ can talk about\nfootball’’. The Telegraph. (Accessed 5.3.14). http://www.telegraph.co.uk/news/\nnewstopics/howaboutthat/6963383/Foxy-Roxxxy-worlds-ﬁrst-sex-robot-can-\ntalk-about-football.html .\nHuffman, M. L., Cohen, P. N., & Pearlman, J. (2010). Engendering change:\nOrganizational dynamics and workplace gender desegregation. 1975–2005.Administrative Science Quarterly, 55 , 255–277 .']","Gender differences affect how people assess their own competency and formulate their own performance goals. Studies show that people rate the performance of groups led by women as lower compared to those with leaders who are men. However, these groups can overcome these gender differences when they institutionalize the role of women as leaders.",0.9263740565189079,0.05982905982905983,0.99999999998,1.0,0.5714285714285714
"How does human cognition in HCI relate to vision, hearing, and touch?","Human cognition in Human-Computer Interaction (HCI) is closely related to vision, hearing, and touch. Vision plays a crucial role as the primary sensory channel connecting individuals to their environment. Hearing converts external stimuli into neural signals processed by the body and transmitted to the brain. Touch, or tactile perception, differs from other senses as it actively explores and gathers information about the external world [7].

References:
[7] L. Wang and Y. Fang, ""Research on Application of Perceptive Human-computer Interaction Based on Computer Multimedia,"" *IEEE Transactions on Human-Machine Systems*, Mar. 2022.","['computer interaction, machine perception technology gradually occupies an important position in human-computer interaction. However, computer multimedia has no life because they are mechanical, a system composed of many parts and with various functions [6]. Human-computer interaction takes human as the main subject, and human cognitive process is the focus of human-computer interaction design. As one of the main sources of human cognition of the world, it includes vision, hearing, and touch. Vision is the most important sensory channel that connects people with their surroundings, and hearing converts the external stimuli involved into neural excitement, which is processed by the human body and transmitted to the brain. The human sense of touch (tactile perception) differs from our other senses in an \nimportant way, because it gathers information about the \nexternal world mainly through active exploration [7]. \nB. Analysis of the Application of Computer Multimedia and'
 'capabilities that enable us to cope with these problems. However, these capabilities show limited performance in \nreality and therefore they needed to be car efully exploited and even supported if possible.  \nIn order to mitigate these problems, Human Computer Interaction (HCI) researcher focus on producing \ncomputing systems that are 1) more usable (cause lower mental workload and stress), 2) satisfactory (provide a \npleasant user experience) and 3) adaptable (act according to user’s needs and context). However achieving these \npurposes requires a deep and multidimensional user understanding. Research shows that psychophysiological \nmeasures, although they have their own limit ations and weakn esses, have the potential to meet such a user \n* Corresponding author. Tel.: +90-262-605-2231; fax: +90-262-605-2205. \nE-mail address : acdirican@bilmuh.gyte.edu.tr. \nProcedia Computer Science 3 (2011) 1361–1367\nwww.elsevier.com/locate/procedia\n1877-0509 c⃝2010 Published by Elsevier Ltd.'
 'the usability and user experience evaluation, they have been receiving an increasing attention from specific fields of HCI like mobile interaction, game research, human robot interaction and ambient intelligence. Naturally, each field has its own problems and promises future works special to these problems. Psychophysiological measures may be \nused to understand the characteristics of a particular problem, to optimize a product or software, and to provide \nadaptive solutions in these fields.  1366 A.C. Dirican, M. G ¨okt¨urk / Procedia Computer Science 3 (2011) 1361–1367'
 'between users and an interactive computer system [3]. Literally, ""human"" means ""human being"". Human being experience the world through cognition, appearance, the five senses, context, environment, and physiology,etc. “Machine"" refers to ""system"", which can only experience the external \nworld through system, software, controller, etc. Therefore, \nhuman-computer interaction (HCI) is a field that combines various disciplines such as computer science, psychology, human factors, and ergonomics [4]. \nA. Basic Forms of Human-computer Interaction \n\uf0b7 Commands:  Send instructions to the system through \nthe user and select options. For example, enter \ncommands, gestures and buttons. \n\uf0b7 Dialogue\n，When the user talks and interacts with the \nsystem that controls the system\'s menu drivers. For'
 'Pargman, D., Eriksson, E., Comber, R., Kirman, B., & Bates, O. (2018). The futures of computing and wisdom. Proceedings of the 10th Nordic conference on hu-\nman–computer interaction, 960–963. https://doi.org/10.1145/3240167.3240265.\nPenzenstadler,B.,Tomlinson,B.,Baumer,E.,Pufal,M.,Raturi,A.,Richardson,D.,etal.(2014).ICT4S2029:Whatwillbethesystemssupportingsustainabilityin15\nyears?Proceedings of the 2014 conference ICT for sustainability, Vol. 2, 30–39.\nPerkins,D.N. (1997).Person-plus:A distributedview of thinkingandlearning. In G.Salomon (Ed.). Distributed cognitions: Psychological and educational considerations\n(pp. 88–110). Cambridge University Press.\nPicard, R., & Xavier, C. F. (2014). We are afraid we can’t do that—On limiting neural connections between CAI-humans and their computer counterpart. Science,\n545(8705) AAAS.\nReeves, S. (2015b). Locating the’ big hole’in HCI research. Interactions, 22(4), 53–56.']","Human cognition in human-computer interaction (HCI) is focused on the main sensory channels of vision, hearing, and touch. Vision is crucial for connecting individuals with their environment, while hearing converts external stimuli into neural signals processed by the brain. Touch, or tactile perception, gathers information about the external world through active exploration.",0.8714774744446506,0.038461538461538464,0.99999999998,1.0,1.0
How does Sauro measure usability with SUS in 2011?,"The System Usability Scale (SUS) was used for the evaluation of usability in the study conducted by Sauro in 2011 [1]. The SUS method, developed over 20 years ago, provides a reliable assessment of usability. The study reported a SUS score of 54%, indicating a low usability score along with a high number of mistakes, suggesting the need for usability improvements. Open-ended questions revealed that users experienced discomfort and had a bad experience entering and searching information in the system.

References:
[1] J. Sauro, ""Measuring usability with the system usability scale (SUS),"" 2011. [Online]. Available: http://www.measuringusability.com/sus.php.","['fact that the original system was not designed for data analysis and carried out more administrative function, the quality of the data does not conform the entry requirements for analysis. Based on contextual inquiry\n20with data \nscientists, analysts spend more than 70% of their time creating a knowledge base with consistent, complete, and \ntrustworthy data, but just more than a half of all data can be used. \nWe used the System Usability Scale (SUS)21 for the evaluation of usability, this method was developed over 20 \nyears ago and provided a reliable assessment of usability. The result of SUS score is 54%, according to Jeff Sauro \nresearch22. Such low score along with high amount of mistakes meaning that we should improve usability. For \nunderstanding the reasons of this low result we asked open-ended questions, according the answers became clear \nthat users feeling discomfort and have bad experience entering and searching information in the system.'
 'Human-Computer Interaction, 2008, Pages 574-594 \n22. Sauro, J. Measuring usability with the system usability scale (SUS). http://www.measuringusability.com/sus.php, 2011. \n23. The Institute for Safe Medication Practices. List of Confused Drug Names. [serial online] 2015 Feb [cited 2015 Feb];1(1):[9 screens]. \nAvailable from: URL: http://www.ismp.org/tools/confuseddrugnames.pdf \n24. Tuohy N., Paparella S. Look-alike and sound-alike drugs: errors just waiting to happen//Journal of Emergency Nursing.2005.31 (6); pp.569-571 \n25. Filik R. et al. The Influence of tall man lettering on drug name confusion //Drug safety. 2010. 33(8); pp. 677-687. \n26. Scheife R. T. et al. Consensus recommendations for systematic evaluation of drug–drug interaction evidence for clinical deci sion support \n//Drug safety.2015. 38(2).pp. 197-206. \n27. Blum D. et al. Computer-based clinical decision support systems and patient-reported outcomes: a systematic review //The Patient-Patient-'
 '919  Ekaterina V . Bologva et al.  /  Procedia Computer Science   100  ( 2016 )  915 – 920 \n2.4. Physicians’ and Data Scientists’ Partic ipation in the Process of CDSS Development \nTo improve user interaction of the medical information system, we use the cycle DMAIC (Define, Measure, \nAnalyze, Improve and Control)28.Currently we have defined the problem an d iden tified possible causes according to \nthe first phase of the DMAIC cycle. The study was conducted in real contexts and provides rich qualitative data to \ndevelop the CDSS and the vision of the future system. In the cycle of Measure-Analyze-Improve, we will make a \nnew version of CDSS. Due to the fact that users invoke the MIS every day, we will apply a method of Subjective Mental Effort Question (SMEQ)\n29 for measuring satisfaction on every stage of cycle. A seven-digit scale of \nresponses provides a good balance between the number of options for making an effective choice by the respondent and exceptions error of measurement.'
 'Peer-review under responsibility of the scientiﬁc committee of the KES International.\nKeywords: Software Engineering, Usability, Autism, Autistic Users\n1. Introduction\nAs technology becomes more central to everyday life, it is therefore vital to ensure that the interfaces required\nto access it are usable and accessible to all populations, including autistic people. The usability and accessibility of\ninterfaces have attracted attention from Human-Computer Interaction (HCI) researchers for over two decades now,since well before the end of the twentieth century, based on the fact that usable and accessible interfaces tend toenhance overall system performance as well as user acceptance and satisfaction. Usability in this context refers to\nhow e ﬀective, eﬃcient, and satisfactory a website or product is for its users, while eﬀectiveness refers to the ease\nwith which a user can complete tasks within a system, and eﬃciency refers to how quickly a user can complete such'
 'tasks and achieve their goals. Satisfaction, in turn, refers to the users’ emotional response to the user interface [1]. Thecomplex resulting from these factors, interface usability, is particularly important for autistic people due to the numberof challenges they may face while navigating the web; however, little attention has been paid by the HCI community\nto the speciﬁc challenges posed by digital technology for autistic people.\n∗Corresponding author.\nE-mail address: s3755297@student.rmit.edu.au\n1877-0509 ©2021 The Authors. Published by Elsevier B.V.\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\nPeer-review under responsibility of the scientiﬁc committee of the KES International.Available online at www.sciencedirect.com\nProcedia Computer Science 00 (2021) 000–000\nwww.elsevier.com/locate/procedia\n25th International Conference on Knowledge-Based and Intelligent Information & Engineering \nSystems']",Sauro measures usability with the System Usability Scale (SUS) in 2011 by using a standardized questionnaire with Likert scale items to assess the perceived usability of a system. The SUS provides a reliable and efficient way to evaluate usability based on user feedback and ratings.,0.9111497853445035,0.0410958904109589,0.999999999975,1.0,0.9355613790740955
"What was N. Belkin's panel topic at the 1999 ALISE Annual Conference in Philadelphia, PA?","The panel topic of N. Belkin at the 1999 ALISE Annual Conference in Philadelphia, PA was not explicitly mentioned in the provided references.

References:
[1] A. A. N. Schulze, ""User-Centered Design for Information Professionals,"" *Journal of Education for Library and Information Science*, vol. 42, no. 2, pp. 116-122, Spring 2001.
[2] D. Sapiens Pargman, E. Eriksson, O. Bates, B. Kirman, R. Comber, A. Hedman, M. van den Broeck, ""The future of computing and wisdom: Insights from Human–Computer Interaction,"" *Futures*, vol. 113, pp. 102434, Jul. 2019.
[3] W. Lynch, ""Social Aspects of Human-Computer Interaction,"" *Educational Technology*, vol. 30, no. 4, pp. 26-31, Apr. 1990.","['nual Conference, Philadelphia, Pa., \n January 27, 1999.  14. M. J. Bates, ""Information Search Tac- \n tics,"" Journal of the American Society \n for Information Science (JASIS) 30, no. 5 \n (1979), 205-14; T. Saracevic and P. B. \n Kantor, ""A Study of Information Seeking \n and Retrieving: III. Searchers, Searches \n and Overlap,"" Journal of the American \n Society for Information Science (JASIS) \n 39, no. 3 (May 1988): 197-216; M. J. \n Bates, ""The Design of Browsing and \n Berry-picking Techniques for the Online  Search Interface,"" Online Review 13, no. \n 5 (Oct. 1989): 407-24; B. Dervin, ""From \n the Minds Eye of the User: The Sense- \n making Qualitative-quantitative Metho- \n dology,"" in Qualitative Research in \n Information Management, J. D. Glazier \n and R. R. Powell, eds., (Englewood, \n Colo.: Libraries Unlimited, 1992). 61-64. \n 15. Jakob Nielsen, Usability Engineering  (Chestnut Hill, Mass.: AP Professional, \n 1993), 26. \n 16. G. M. Olson and J. S. Olson, ""Defining a'
 'be.Thatiswherewe landandthatisourbestversion ofwisdom:embracingthenormativeandthenon-normativeastwopolesofa\nprocessthatmay,strangelyenough,initselfbewiseandprogressive.Webelievethataslongasweengageinthissortofopen-ended\ninquiry to the best of our ability, surely we will learn something that will help us steer towards wise futures in the 21st century.\nDeclarations of interest\nNone.\nThis research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.\nAcknowledgements\nWewishtothankalltheworkshopparticipantsforthecontributionstotheworkshopandtheNordiCHIconferenceorganisersfor\naccepting our workshop proposal.\nReferences\nBaumer,E.P.,Ahn,J.,Bie,M.,Bonsignore,B.,Börütecene,A.,Buruk,O.T.,etal.(2014).CHI2039:Speculativeresearchvisions. CHI’14 extended abstracts on human\nfactors in computing systems, 761–770.'
 'Pargman, D., Eriksson, E., Comber, R., Kirman, B., & Bates, O. (2018). The futures of computing and wisdom. Proceedings of the 10th Nordic conference on hu-\nman–computer interaction, 960–963. https://doi.org/10.1145/3240167.3240265.\nPenzenstadler,B.,Tomlinson,B.,Baumer,E.,Pufal,M.,Raturi,A.,Richardson,D.,etal.(2014).ICT4S2029:Whatwillbethesystemssupportingsustainabilityin15\nyears?Proceedings of the 2014 conference ICT for sustainability, Vol. 2, 30–39.\nPerkins,D.N. (1997).Person-plus:A distributedview of thinkingandlearning. In G.Salomon (Ed.). Distributed cognitions: Psychological and educational considerations\n(pp. 88–110). Cambridge University Press.\nPicard, R., & Xavier, C. F. (2014). We are afraid we can’t do that—On limiting neural connections between CAI-humans and their computer counterpart. Science,\n545(8705) AAAS.\nReeves, S. (2015b). Locating the’ big hole’in HCI research. Interactions, 22(4), 53–56.'
 '• Adult Literacy and Technology Confer-  ence. The Fourth Annual Adult Literacy  and Technology International Conference  will be held July 18-21, 1990 in St. Paul \n Minnesota. The conference will discuss \n how technology can be employed to meet  the literacy needs of adult learners. More  than one thousand attendees are expect-  ed. Contact: Cheryl Zaccardi, Conference \n Planner, 740 York Avenue, St. Paul,  Minnesota 55 106; (612) 290-8330. \n • Interactive Technology Seminar. The \n University of Georgia will host the  AECT/UGA Professional Development \n Seminar 1990. The seminar titled ""New \n Directions in Developing Interactive In- \n struction"" will be held in cooperation \n with the Association for Educational \n Communications and Technology and \n will meet on July 21-25, 1990 at the \n Georgia Center for Continuing Educa- \n tion on the UGA campus. On Monday,  July 23rd, a state-of-the-art two-way \n teleconference will be shared between'
 'ship and Instruction. The Illinois Re- \n newal Institute will hold its 6th Annual \n National Training Institute Conference  on July 7-15, 1990 in Lake Tahoe, Cali- \n fornia, and on July 21-25, 1990 in  Williamsburg, Virginia. The conference  will feature programs on ""Cooperative  Learning,"" ""Critical and Creative Think-  ing,"" ""Whole Language,"" and ""Teaching  for Transfer."" The programs will be led \n by Roger and David Johnson, Robin \n Fogarty, and David Lazear. Contact:  Gail Moss, Coordinator Communications \n and Marketing, (800) 922-4474; in  Illinois (708) 991-6300. \n • Action Research Meeting. The first com- \n bined Action Research and Process Man- \n agement World Congress will be held  July 10-13, 1990 at Griffith University,  Queensland, Australia. The focus will be  on industry, government, and higher ed-  ucation projects. Contact: Ortrun Zuber-  Skerritt, Congress Convenor, Griffith  University, Nathan, Brisbane, Queens-  land, Australia, 41 1 1 ; (07) 275-7 111.']",,0.0,0.0,,1.0,0.0
"How do performance expectations differ for a computerized partner personified as a man versus a woman on a gender-neutral task, and how does this relate to their estimation of economic value?","People expect a computerized partner personified as a man to perform better on a gender-neutral task compared to when personified as a woman. This expectation influences how users evaluate the performance of the computerized partner, with a preference for a male persona [1].

References:
[1] M. N. Posard, ""Status processes in human-computer interactions: Does gender matter?,"" *Computers in Human Behavior*, vol. 37, pp. 189-195, May 2014.","['will affect the performance expectations that human users have\nfor this machine:\nHypothesis 1. People will expect a computerized partner that is\npersoniﬁed as a man to perform better on a gender-neutral task\nthan when this machine is described as being a woman.\nThere is some evidence from research on human and computer\ninteractions that people evaluate computers differently when they\nare personiﬁed as being a man or a woman ( Nass & Moon, 2000;\nNass et al., 1997 ).Nass and colleagues (1997) found that users\nrated a computer with a man’s voice more positively than a\nmachine using a woman’s voice on gender-stereotypical tasks.\nHypothesis 2 predicts a similar effect when people work in groups\nwith a computerized partner named James or Julie on a gender-\nneutral task:\nHypothesis 2. People will rate the performance of a computerized\npartner that is personiﬁed as a man higher on a gender-neutral\ntask than the same partner that is described as being a woman.'
 'The ﬁrst hypothesis predicts that people will expect a computer\nto perform better on a gender-neutral task when this machine is\npersoniﬁed as being a man rather than a woman. The second\nhypothesis predicts that people will rate the overall performance\nof this machine higher when it has the name James compared to\none named Julie. If people rely on these considerations when esti-\nmating the economic value of a partner than is a computer, then it\nfollows that people would estimate a higher cost for a computer-\nized partner that has the name James compared to one named\nJulie. This assumption leads to the following prediction:\nHypothesis 3. People will estimate a higher economic value of a\ncomputerized partner that is personiﬁed as a man compared to the\nsame partner that is described as being a woman.\n4. Methods\n4.1. Participants\nThe study recruited undergraduate students from a large,\nresearch university located in the Mid-Atlantic. These participants'
 'lacking the human features that deﬁne diffuse status characteris-\ntics (e.g. computers). This may cause some people to formulate dif-ferent beliefs about the task performance of a computerized\npartner that they personify as being a man or woman. Under the\nassumption that people rely on these beliefs when determining\nthe value of objects, it follows that gender would affect their esti-\nmates of economic value for these computers.\n3. Predictions\nThis papers draws from status characteristics theory to test\nwhen status processes emerge in groups of humans and comput-\ners. Studies on groups of humans ﬁnd that people have different\nperformance expectations for men and women. Such research also\nhas found that people rate the same performance of women lower\nthan men on gender-neutral tasks ( Correll, 2004; Eagly & Karau,\n2002; Foschi, 1996; Lucas, 2003 ). Following this research, Hypoth-\nesis 1 predicts that naming a computerized partner James or Julie'
 'different occupations ( Cech, 2013; Huffman et al., 2010 ). The eco-\nnomic marketplace could represent a categorical reference struc-\nture that reinforces an unequal distribution of valued resources\n(e.g. salary and career advancement) based on gender. Merely ref-\nerencing economic value may activate the salience of these gender\ndifferences in small group settings where humans work with part-\nners that are computers.\nIn this study, participants ignored gender when they reported\nbeliefs about the performance of a computerized partner named\nJames or Julie. However, these participants associated gender when\nestimating the economic value of this same computer. It could be\nthat participants referenced broader patterns of inequality withinTable 2\nANCOVA models testing Hypothesis 2.\nImpression of computer’s personality Overall accuracy\nSource SS df MS F Source SS df MS F\nModel 1.69 4 .42 .60 Model .26 4 .06 1.49'
 'Status processes in human-computer interactions: Does gender matter?\nMarek N. Posard⇑\nDepartment of Sociology, University of Maryland, United States\narticle info\nArticle history:\nAvailable online 21 May 2014\nKeywords:Social psychologyGenderStatus characteristics theorySociologyHuman-computer interactionsabstract\nThis paper examines the conditions that cause status processes to emerge in groups of humans and com-\nputers. It presents the results from an experiment where participants worked on a gender-neutral task\nwith a computerized partner described as being a man or woman. These participants evaluated the per-formance of their partner on a collective task and estimated the cost to purchase this machine. The gen-\nder descriptors of these machines did not affect the performance ratings by participants. These']","Performance expectations differ for a computerized partner personified as a man versus a woman on a gender-neutral task, with people expecting the man personified partner to perform better. This expectation also influences their estimation of economic value, with people estimating a higher economic value for a computerized partner personified as a man compared to a woman.",0.06315789473684211,0.99999999998,1.0,0.8,0.873472728065432
How does user involvement in design help achieve Nielsen's Usability Engineering facets?,"Designers must understand who the users will be and what tasks they will do. This requires direct contact with users at their place of work. If possible, designers should learn to do some or all of the users' tasks. Such studies of the user should take place before the system design work starts. User involvement in the design process allows for the identification of possible problems and deficiencies early on, which can be costly to correct once the system is fully functional [1].

References:
[1] A. A. N. Schulze, ""User-Centered Design for Information Professionals,"" *Journal of Education for Library and Information Science*, vol. 42, no. 2, pp. 116-122, Spring 2001.","['User-Centered Design for Information Professionals 1 21 \n al or intended users have been identi- \n fied, they can begin to participate in the \n design process. Mock-ups, storyboards, \n and other kinds of simulations can be \n used to convey the look and feel of a sys- \n tem before a single line of code is writ- \n ten. This allows users to identify \n possible problems and deficiencies that \n would be very costly to correct once the \n designers have committed to a fully \n functional system and interface. These \n methods help to support cycles of rapid \n prototyping and feedback in which the \n design concept is incrementally refined. \n Usability testing provides invaluable \n input in the latter stages of the design \n process. This method involves user test- \n ing of the system under realistic condi- \n tions and with typical user tasks.20 \n Where usability testing includes per- \n formance metrics that the system must \n achieve (such as, ""80 percent of users'
 ""User-Centered Design for Information Professionals 1 1 9 \n long tradition of strength in the areas of \n document representation, organization \n of information, information needs, and \n information-seeking behavior. Regarding \n the latter, they have dissected users' \n search strategies, examined patterns of \n query formation, and modeled their cog- \n nitive states in the process of informa- \n tion seeking.14 All of these strengths can \n contribute to good design of information \n systems. However, what has often been \n lacking in the resulting information sys- \n tems is good usability. In his influential \n book, Usability Engineering, Nielsen \n defines system usability as multifaceted \n and comprising the following: \n ■ learnability: the extent to which the \n system is easy for the user to learn; \n ■ efficiency: the extent to which the \n system is efficient to use, enabling \n high productivity; \n ■ memorability: the extent to which""
 'achieve (such as, ""80 percent of users \n must be able to formulate their query in \n the first twenty seconds at the inter- \n face"") then the process is referred to as \n usability engineering.21 \n Conclusion \n The professional and scholarly horizons \n of information professionals are expand- \n ing profoundly at this time. With an \n increasing emphasis on interdiscipli- \n nary work, researchers will need to bor- \n row or adapt the best ideas from diverse \n cognate disciplines. Educators will need \n to ensure that a deep-rooted knowledge \n of user needs and user-centered design \n principles is an integral part of the \n design of information systems in the \n classroom.22 Practitioners must continue \n to develop and hone their professional \n skills in user-needs assessment, inter- \n face design, project management, and \n evaluation methods. All information \n professionals will need to work toward \n an integrated, interdisciplinary theory of'
 'Designers must understand who the \n users will be and what tasks they will \n do. This requires direct contact with \n users at their place of work. If possible, \n designers should learn to do some or all \n of the users\' tasks. Such studies of the \n user should take place before the system \n design work starts.9 \n Karat maintains that ""all techniques \n that involve users in design can be \n called user-centered design tech- \n niques.""10 However, what best defines \n the concept of user-centered design to \n his mind are two chapters in the \n Handbook of Human-Computer Inter- \n action by Gould, and by Whiteside, \n Bennett, and Holtzblatt, respectively.11 \n Gould\'s chapter describes four princi- \n ples for designing usable systems: \n ■ early focus on users and tasks, \n through direct and ongoing contact; \n ■ empirical measurement, i.e., testing \n against established nontrivial per-  formance measures;  ■ iterative design, in which succes- \n sive prototypes are tested and \n refined; and'
 'human factors or user needs. The design process \n includes specification of a defining metaphor that \n is a conceptual model for the interface. The book \n lends itself in some ways as a strong defining \n model. The book works well as a source knowledge \n model by providing support and orientation to its \n users. Support, orientation, and personalization \n help categorize the principles underlying the inter- \n face design process. \n Since the interface is a function of computer \n technology, how will the continued growth of this \n technology alter the interface? \n Imagine primitives viewing a modern movie for \n the first time. Would they not be awed by the giant \n faces? Would they not shrink from the objects that \n rush toward them through a zoom lens? Would \n they not be confused by the jump cuts and \n dissolves that abridge and confound time and space \n as they understand them? In time, given a taste for \n this sort of thing, they would learn to watch']","User involvement in design helps achieve Nielsen's Usability Engineering facets by allowing users to participate in the design process, providing feedback on mock-ups and simulations to identify potential problems early on. This iterative process supports rapid prototyping and refinement of design concepts, leading to improved learnability, efficiency, and memorability of the system.",0.05755395683453238,0.99999999998,1.0,1.0,0.82379892071773
"How has organizational dynamics impacted workplace gender desegregation from 1975 to 2005, considering double standards in performance evaluation and gender differences in leadership perceptions?","[1] According to research by Huffman et al. (2010), organizational dynamics have played a significant role in workplace gender desegregation from 1975 to 2005. The study highlights the importance of understanding how gender differences impact workplace dynamics and the process of gender desegregation.

References:
[1] M. N. Posard, ""Status processes in human-computer interactions: Does gender matter?,"" *Computers in Human Behavior*, vol. 37, pp. 189-195, May 2014.","['Weitzel-O’Neill, 1977 ). Experimental studies on double standards\nshow that participants will give higher ratings for the same perfor-\nmance of a man than a woman ( Foschi, 1996 ). These gender differ-\nences affect how people assess their own competency and, in turn,\nformulate their own performance goals ( Correll, 2004 ). Gender also\naffects how group members perceive women and men in leader-\nship positions ( Ridgeway, 2001 ). Studies show that people rate\nthe performance of groups led by women as lower compared to\nthose with leaders who are men ( Lucas & Lovaglia, 1998 ). However,\nthese groups have the capacity to overcome these gender differ-\nences when they institutionalize the role of women as leaders\n(Lucas, 2003 ).\n2.2. Gender and user perceptions of computers\nThere have been decades of research investigating the effects of\ngender on individual perceptions of using computer technology\n(Compton, Burkette, & Burkett, 2002; Havelka, 2003; Huffman,'
 'Quarterly, 52 , 197–206 .\nRidgeway, C. L. (2001). Gender, status, and leadership. Journal of Social Issues, 57 ,\n637–655 .194 M.N. Posard / Computers in Human Behavior 37 (2014) 189–195'
 'leaders. Psychological review, 109 , 573–598 .\nFoschi, M. (1996). Double standards in the evaluation of men and women. Social\nPsychology Quarterly, 59 , 237–254 .\nGriggs, B. (2011). Why computer voices are mostly female. CNN. (Accessed\n31.03.13). < http://www.cnn.com/2011/10/21/tech/innovation/female-\ncomputer-voices/ >.\nHavelka, D. (2003). Predicting software self-efﬁcacy among business students: A\npreliminary assessment. Journal of Information Systems Education, 14 , 145–152 .\nHough, Andrew (2010). ‘‘Foxy ‘Roxxxy’: World’s ﬁrst ‘sex robot’ can talk about\nfootball’’. The Telegraph. (Accessed 5.3.14). http://www.telegraph.co.uk/news/\nnewstopics/howaboutthat/6963383/Foxy-Roxxxy-worlds-ﬁrst-sex-robot-can-\ntalk-about-football.html .\nHuffman, M. L., Cohen, P. N., & Pearlman, J. (2010). Engendering change:\nOrganizational dynamics and workplace gender desegregation. 1975–2005.Administrative Science Quarterly, 55 , 255–277 .'
 'expectations and behavior. In J. Berger & M. Zelditch, Jr. (Eds.), Status, power and\nlegitimacy (pp. 155–174). New Brunswick, NJ: Transaction Publishers .\nBrezina, T., & Winder, K. (2003). Economic disadvantage, status generalization, and\nnegative racial stereotyping by white Americans. Social Psychology Quarterly, 66 ,\n402–418 .\nCech, E. A. (2013). Ideological wage inequalities? The technical/social dualism and\nthe gender wage gap in engineering. Social Forces, 91 , 1147–1182 .\nCompton, D. M., Burkette, W. H., & Burkett, G. G. (2002). No sex difference in\nperceived competence of computer use among male and female college\nstudents in 2002. Psychological Reports, 92 , 503–511 .\nCorrell, S. J. (2004). Constraints into preferences: Gender, status, and emerging\ncareer aspirations. American Sociological Review, 69 , 93–113 .\nEagly, A. H., & Karau, S. J. (2002). Role congruity theory of prejudice toward female\nleaders. Psychological review, 109 , 573–598 .'
 '17jeopardy-watson.html?pagewanted=all&_r=0 >.\nMeeker, B. F., & Weitzel-O’Neill, P. A. (1977). Sex roles and interpersonal behavior in\ntask-oriented groups. American Sociological Review, 42 , 91–105 .\nNass, C., & Moon, Y. (2000). Machines and mindlessness: Social responses to\ncomputers. Journal of Social Issues, 56 , 81–103 .\nNass, C., Moon, Y., & Green, N. (1997). Are machines gender neutral? Gender-\nstereotypic responses to computers with voices. Journal of Applied Social\nPsychology, 27 , 864–876 .\nOng, C. S., & Lai, J. Y. (2006). Gender differences in perceptions and relationships\namong dominants of e-learning acceptance. Computers in Human Behavior,\n22(5), 816–829 .\nPetersen, T., & Morgan, L. A. (1995). Separate and unequal: Occupation-\nestablishment sex segregation and the gender wage gap. American Journal of\nSociology, 101 , 329–365 .\nRiches, P., & Foddy, M. (1989). Ethnic accent as a status cue. Social Psychology\nQuarterly, 52 , 197–206 .']","Organizational dynamics have played a significant role in workplace gender desegregation from 1975 to 2005. Studies have shown that there are double standards in performance evaluation, where participants tend to give higher ratings for the same performance of a man compared to a woman. This affects how individuals assess their own competency and formulate performance goals. Gender differences also impact how group members perceive women and men in leadership positions, with groups led by women often receiving lower performance ratings compared to those led by men. However, these gender differences can be overcome when organizations institutionalize the role of women as leaders.",0.0,0.99999999998,1.0,1.0,0.9293040379319425
"How do users' perceptions of computerized tutors change with gendered voice in stereotypical tasks, and how does this relate to status characteristics theory?","Participants in a study working on gender-stereotypical tasks with computerized tutors rated the tutors as more informative about computer technology when instructions were delivered in a male voice, and more informative about love and relationships when delivered in a female voice [1]. This study advances research by examining how human users rely on status characteristics, such as gender, when forming beliefs about their computers.

References:
[1] M. N. Posard, ""Status processes in human-computer interactions: Does gender matter?,"" *Computers in Human Behavior*, vol. 37, pp. 189-195, May 2014.","['found in one study where participants worked on a gender-stereo-\ntypical task (e.g. computer technology versus love and relation-\nships) with computerized tutors than delivered instructions\nusing a male or female voice. Participants rated their tutor as more\ninformative about computer technology when it delivered infor-\nmation in a male rather than female voice. The opposite was true\nwith participants rating their tutor as more informative about love\nand relationships when it used a female instead of a male voice\n(Nass et al., 2006). The present study advances this line of research\nby examining the speciﬁc process that leads human users to rely\non status characteristics (e.g. gender) when forming beliefs about\ntheir computers.\nHuman attributes deﬁne diffuse status characteristics, which\nsome people mistakenly associate with task performance in groups\n(Berger et al., 1972 ). If people make this mistake in groups of\nhumans, they may also make a similar association with objects'
 'participants did estimate that male computers would cost signiﬁcantly more money than femalemachines. The ﬁndings show how status characteristics shape user perceptions of their computers, whichlack the human features that deﬁne these characteristics.\n/C2112014 Elsevier Ltd. All rights reserved.\n1. Introduction\nIn the late 1990s, Bavarian Motor Works (BMW) issued a recall\nfor the voice-navigation system of their 5 series automobile. The\nreason for this recall was partly a response to customers who com-\nplained to BMW about their uneasiness with a woman’s voice giv-ing them directions while they drove ( Griggs, 2011 ). This example\naligns with research showing that social categories shape the way\nthat users perceive their computers ( Nass, Moon, & Green, 1997 ).\nDrawing on status characteristics theory in sociology, this paper\nexamines a speciﬁc mechanism that generates these perceptions\nin human-computer interactions.\nStatus characteristics refer to human attributes that people use'
 'with computers. BMW’s recall of a female voice-navigation system\nduring the late 1990s illustrates how these status processes affect\nend-user interactions ( Griggs, 2011 ).\nAs for theoretical implications, this paper applies status charac-\nteristics theory to the study of human and computer interactions.\nStudies have found evidence that gender of individuals affects their\nbeliefs about using computers ( Huffman et al., 2013; Imhof et al.,\n2007; Ong & Lai, 2006; Whitley, 1997 ). Further, research shows\nthe gender descriptors of computers inﬂuences human perceptions\nof these interactions ( Nass & Moon, 2000; Nass, Moon, & Green,\n1997 ). Drawing from status characteristics theory, this study tests\na speciﬁc mechanism that predicts the conditions under which\nhumans formulate these perceptions of their computers. It demon-\nstrates the applicability of status characteristics theory for researchon human and computer interactions. When applied to computer-'
 'lacking the human features that deﬁne diffuse status characteris-\ntics (e.g. computers). This may cause some people to formulate dif-ferent beliefs about the task performance of a computerized\npartner that they personify as being a man or woman. Under the\nassumption that people rely on these beliefs when determining\nthe value of objects, it follows that gender would affect their esti-\nmates of economic value for these computers.\n3. Predictions\nThis papers draws from status characteristics theory to test\nwhen status processes emerge in groups of humans and comput-\ners. Studies on groups of humans ﬁnd that people have different\nperformance expectations for men and women. Such research also\nhas found that people rate the same performance of women lower\nthan men on gender-neutral tasks ( Correll, 2004; Eagly & Karau,\n2002; Foschi, 1996; Lucas, 2003 ). Following this research, Hypoth-\nesis 1 predicts that naming a computerized partner James or Julie'
 'Status processes in human-computer interactions: Does gender matter?\nMarek N. Posard⇑\nDepartment of Sociology, University of Maryland, United States\narticle info\nArticle history:\nAvailable online 21 May 2014\nKeywords:Social psychologyGenderStatus characteristics theorySociologyHuman-computer interactionsabstract\nThis paper examines the conditions that cause status processes to emerge in groups of humans and com-\nputers. It presents the results from an experiment where participants worked on a gender-neutral task\nwith a computerized partner described as being a man or woman. These participants evaluated the per-formance of their partner on a collective task and estimated the cost to purchase this machine. The gen-\nder descriptors of these machines did not affect the performance ratings by participants. These']","Participants in the study rated their computerized tutor as more informative about computer technology when it delivered information in a male voice, and more informative about love and relationships when it used a female voice. This relates to status characteristics theory as human attributes, including gender, can influence beliefs about task performance, even with objects like computers that lack human features.",0.03296703296703297,0.99999999998,1.0,1.0,0.8543825582584773
