question,answer,contexts,ground_truth,context_relevancy,context_precision,context_recall,faithfulness,answer_relevancy
How does the CNN-based model struggle to classify sentiment accurately in certain cases?,"The CNN-based model struggles to classify sentiment accurately in certain cases when it predicts positive for all sentiment aspects, even when the sentiment should be negative. This issue arises when certain words, like 'okay', have a moderately high probability across all aspects, leading to misclassification. Additionally, longer phrases with more than 5 words can pose challenges for the CNN-based model in processing and identifying the correct sentiment [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['product is okay, delivery time and process of confirming the purchase should be improved next time”) the CNN-based model fails to classify the right sentiment by predicting positive for all sentiment aspects. The ‘service’ \nand ‘delivery time’ aspects should be negative in this \ncase. This case is caused by the word ‘okay’ which has moderately high probability in all aspects. The phrase, which signal the sentiment is negative, is also quite long (having more than 5 words) so CNN-based has difficulty on processing it. \nThere are some sentences which none of our models \nget these sentences right. For instance, “Pelayanan ya \nsangat buruk ga ada respon sama sekali baik pertanyaan ataupun keluhan” (“Bad service, no response for both \nquestions or complaints”), “sip dipertahankan yang akan \ndatang kecepatan pengirimannya ya jangan sampai ada \nyang ketinggalan ketinggalan lagi paketnya ...”  (“Yep,'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'texts into French, German, and Spanish [6]. Although they \nclassified sentiments using Support Vector Machine that is \ntrained with translated texts, classification accuracy was not \nsufficient in their experimental results. In the results of these \npapers, one of the most serious causes on the performance \ndegradation is considered as an error of translation for each text. \nCan et al.  initially built a machine learning model using \nrecurrent neural networks for texts included in English reviews \n[7]. Furthermore, the learning model applied for texts on other \nlanguages. In the classification experimental results, they \nclaimed that machine translation does not affect the \nperformance because translation errors are not noticeable and \nnecessary information for sentiment analysis are not lost. Other \nresearches also reported that sentiment analysis performance is \nnot significantly affected by machine translation results [8, 9].'
 'better understanding of the misclassified data. In sentence \n“Barang sudah diterima dan sudah uji quality semua berfungsi dengan baik, hanya beda sama yang digambar”  \n(“The product has already been received and the quality has been tested, all functionality is good, just different from its picture”), the label of ‘accuracy’ aspect and \n‘quality’ aspect are negative and positive respectively. The GRU sentiment classification model predicts it \ncorrectly but CNN-based gets it wrong on ‘accuracy’ \naspect. The result on ‘accuracy’ and ‘quality’ in CNN-based is 0.509 and 0.83 respectively which shows that ‘accuracy’ value is a small point away to be predicted as negative. In this case, it indicates the model prediction is not completely wrong. \nIn other sentence “Barang oke, kecepatan pengiriman \ndan input resi ditingkatkan yang akan datang”  (“The'
 'The second approach of sentiment classification \nmodel, as given in Figure 5, receives word vectors which  \n2018 International Conference on Asian Language Processing (IALP) 64\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'known so far, deep learning-based approach has been used only once to solve Indonesian aspect-based sentiment analysis. Different to Cahyadi and Khodra [9], instead of using three components, we chose to divide the process into two modules with a general model of aspect \nsentiment classification. We employ different deep \nlearning models in sentiment classification, RNN and CNN. \nThis paper is organized in the following manner. \nSection 2 discusses related works. Section 3 discusses the proposed method. Section 4 shows the experimental and \nevaluation results. Finally, the conclusion and future \nworks are in section 5. \nII. R\nELATED WORKS  \nIn this section, we present some previous works which \nare related on aspect-based sentiment analysis. In 2014, \n2015, and 2016, the Semantic Evaluation provided dataset'
 '‘food’ and ‘service’ aspects are positive and negative respectively.  Data can be extracted from any sources like \nwebsites, newspapers, or social media. However, extracting the sentiment polarity from these sources is not \neasy. Many contests are held to solve this kind of problem such as, task 4 in SemEval-2014 (SE-ABSA14) [1], task \n12 in SemEval-2015 (SE-ABSA15) [2], and task 5 in \nSemEval-2016 (SE-ABSA16) [3]. Many approaches are used, from traditional model into more complex one like deep neural network.  \nRecently, deep learning-based approach has become a \npowerful technique to address this problem, such as Long \nShort-Term Memory [4], GRU [5], and CNN. However, there have been a few studies conducted to solve this problem in Indonesian language. Some of them use Support Vector Machine (SVM) and Naïve Bayes Classifier [6, 7]. Ekawati and Khodra [8] uses Conditional \nRandom Field (CRF). Based on the research we have'
 'detection; sentiment classification; Indonesian; deep neural \nnetwork \nI.  INTRODUCTION  \nSentiment analysis is becoming one of the important \ntopics in natural language processing (NLP). It identifies \nand extracts subjective information then classifies them into three following polarities: positive, negative, and neutral. However, regular sentiment analysis can only identify one polarity for each sentence. Whereas it is possible that one sentence can have different sentiment \npolarities at once. For such reason, aspect-based sentiment \nanalysis is needed. \nAspect-based sentiment analysis is a task to find the \nsentiment polarity of each predefined aspects which expressed in a document. The sentiment polarity of a \nsentence is dependent on both content and aspect. For \nexample, in the sentence “The food is delicious, but the \nservice is too slow.”, the expected sentiment polarity of'
 'delivery time should be keep this way in the future, do not allow any more package left behind...”). The first example is actually quite easy for us to understand, the label should be positive in ‘communication’ but the model gets it \nwrong because word ‘response’ is commonly associated \nwith fast or slow in our training data. A phrase like ‘there is no response’ is very rare. The second sentence is a little bit tricky, the reviewer gave a good opinion but present evidence of bad act (there is “package left behind”, which should be considered as a negative sentiment). \nVI. C\nONCLUSION  \nIn this paper, we propose two different approaches for \nsolving aspect-based sentiment analysis. The first one uses state-of-the-art of text classification using deep neural network for both modules of aspect-based \nsentiment analysis: aspect detection and sentiment']","The CNN-based model struggles to classify sentiment accurately in certain cases because it predicts positive for all sentiment aspects, even when the sentiment is negative. This is often caused by certain words like 'okay' having moderately high probability in all aspects, making it difficult for the model to differentiate. Additionally, long phrases with more than 5 words can also pose challenges for the model in processing and identifying the correct sentiment.",0.020134228187919462,0.99999999999,1.0,0.8,0.9669914158703657
How does the approach of using predefined aspects differ from the aspect-specific sentiment extraction model in the context of sentiment classification?,"Aspect-specific sentiment extraction models differ from the approach of using predefined aspects in the context of sentiment classification by focusing on different aspects of sentiment analysis. The aspect-specific sentiment extraction model, as mentioned by Jebbara and Cimiano [14], emphasizes classifying the sentiment of each aspect identified by the aspect detection model. In contrast, the approach of using predefined aspects does not pay attention to the corresponding terms of aspects and utilizes a set of predefined aspects for sentiment classification.

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'with annotation along some baselines for aspect-based sentiment analysis [1,2,3]. The baseline of aspect detection and sentiment classification use SVM. It also had term extraction process which occurs at some domains. The model could benefit from the exact location \nof aspect’s term because polarity tends to be determined \nby near adjective words. Before extracting aspect, sentence could be filtered by subjectivity classifier [10]. Sentence having sentiment must be subjective. Performing subjectivity classifier would decrease objective sentence so aspect detection model could focus more to label other \nthan none aspect, this aspect is present in some models.  978-1-7281-1175-9/18/$31.00 c⃝2018 IEEE 62\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'a sentence is predicted not having a certain aspect, its label in that aspect is none. Otherwise, the sentence and the aspect are pipelined to sentiment classification. We compare two approaches in the sentiment classification. The first approach use Bi-GRU to classify the sentiment \nof each aspect resulted by the aspect detection model. It is \nsimilar to aspect-specific sentiment extraction model from Jebbara and Cimiano [14] but we use different features. The other differences are the use of predefined aspects and we do not pay attention to the corresponding terms of aspects. The input layer consists of a set of word vectors \nw\ni which is concatenated with their corresponding \nsentiment embedding si and POS tag pi for each word. The \nsentiment embedding is taken from sentiment lexicon'
 'the original word vector is passed onto the aspect \nsentiment classification model to get the sentiment class for each aspect. The flow is shown in Figure 1. \n \nFigure 1. Process Flow of the Aspect based Sentiment Analysis \nA. Aspect Detection Model \n Such as mentioned in previous paragraph, there are \ntwo compared approaches in the aspect detection model. The first approach on this model adopts RNN for handling \naspect detection. The input is a word embedding vector \nwhich is calculated by word2vec approach [18]. \n \nFigure 2. First Approach of Aspect Detection Model \nThere are two layers of GRU, where the first GRU \nreturns a sequence of input for the second GRU. We connect the last output state of the second GRU to a fully \nconnected layer with sigmoid activation function. The  \n2018 International Conference on Asian Language Processing (IALP) 63'
 'produce probability of every word occurred in every aspect as well. This probability will be used as input in sentiment classification model. Xue and Li [17] use Gated-CNN to do the sentiment classification. The aspect feature controls the propagation of sentiment with aspect \nembedding of the given aspect category. \nWhile in Indonesian, Fachrina and Widyantoro [7] \ndevelop aspect-sentiment classification in opinion mining using the combination of rule-based and machine learning. The algorithm they use for machine learning are \nSVM and naïve bayes classifier. Gojali and Khodra [6] \nuse supervised learning for subjectivity classification. They use naïve bayes classifier and SVM to classify sentences and CRF for information extraction. Ekawati and Khodra [8] build a system consists of three steps: aspect detection, aspect categorization, and sentiment \nclassification. Cahyadi and Khodra [9] build a similar'
 'known so far, deep learning-based approach has been used only once to solve Indonesian aspect-based sentiment analysis. Different to Cahyadi and Khodra [9], instead of using three components, we chose to divide the process into two modules with a general model of aspect \nsentiment classification. We employ different deep \nlearning models in sentiment classification, RNN and CNN. \nThis paper is organized in the following manner. \nSection 2 discusses related works. Section 3 discusses the proposed method. Section 4 shows the experimental and \nevaluation results. Finally, the conclusion and future \nworks are in section 5. \nII. R\nELATED WORKS  \nIn this section, we present some previous works which \nare related on aspect-based sentiment analysis. In 2014, \n2015, and 2016, the Semantic Evaluation provided dataset'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'price. The average of aspect occurrences in a sentence is 0.98. Each sentiment aspect can be classified as positive or negative. The statistics of the datasets are shown in Table I.  \nB. Experiments \nWe used different settings for different models. For \naspect detection model, the first approach used Adagrad optimizer with learning rate 0.01. We applied weight constraint in dense layer and dropout in recurrent layer. The second approach used Adam optimizer with learning rate 0.00025 and dropout rate 0.5 is applied. We did early \nstopping to both approaches to prevent overfitting. \nBefore performing the whole experiment, we compare \ntwo baselines of aspect model. One should be chosen so two baselines of sentiment classification model could also be compared fairly. Evaluation on aspect detection result is done by comparing average f1-score value which is \nshown at Table II. The fully-connected baseline is inferior']","The approach of using predefined aspects differs from the aspect-specific sentiment extraction model in that it does not pay attention to the corresponding terms of aspects and uses different features. Additionally, the input layer consists of word vectors concatenated with their corresponding sentiment embeddings and POS tags for each word, with sentiment embeddings taken from a sentiment lexicon.",0.03773584905660377,0.8338789682435448,1.0,1.0,0.9766336301888713
"How does the F1-score of the GRU baseline compare to the Fully-Connected baseline in the aspect model, given GRU's advantages on certain words in the test dataset due to word embeddings?","The F1-score of the GRU baseline compared to the Fully-Connected baseline in the aspect model shows that the GRU baseline outperforms the Fully-Connected baseline. Specifically, the F1-score for the GRU baseline is 0.8855, while the F1-score for the Fully-Connected baseline is 0.8527 [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['to GRU baseline because GRU baseline has advantages on some words which only occur at test dataset by using word embedding. \nTABLE II. F1-score for each baseline of aspect model \nModel Precision Recall F-score \nGRU 0.8936 0.8775 0.8855 \nFully-Connected 0.8367 0.8693 0.8527 \n \nFor sentiment classification model, the first approach \nhas some features as stated before. We did some experiments by using combination of features as shown in Table III. The highest result is obtained with the combination of word embeddings (WE), sentiment lexicons (SL), and POS tags (POS). It can perform well \nfor predicting both positive and negative labels. \nTABLE III. Average weighted F1-score with different features \nFeature Pos Neg Avg \nWE 0.8843 0.6475 0.8547 \nWE+SL 0.8833 0.6543 0.8545 \nWE+POS 0.8850 0.6505 0.8555 \nWE+SL+POS 0.8852 0.6575 0.8563 \n \nThe second approach use setup from Kim [15].'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'embedding which is pre-trained on 27 million sentences \nof Indonesian news data. For each word, similarity function would be computed relative to aspect’s name. \nEvaluation done to all aspects in test dataset result which \nis the output of the better aspect model. Table IV shows that using general word embedding does not benefit as much as using the weights on aspect model because aspect model could distinct words related to aspect better. \nTABLE IV. Average weighted F1-s_core with different choice of aspect \nmatrix. \nAspect Matrix Pos Neg Avg \nAspect Model 0.8803 0.6366 0.8535 \nGeneral Word Embedding 0.8540 0.4502 0.8194 \nTABLE V. Evaluation comparison of different methods \nAspect Model Pos Neg Avg \nAccuracy Fachrina 0.9142 0.5333 0.8601 \nGRU-based 0.9260 0.6474 0.8965 \nCNN-based 0.9303 0.6716 0.9044 \nPrice Fachrina 0.9114 0.4000 0.8927 \nGRU-based 0.8571 0.4000 0.8520 \nCNN-based 0.8547 0.2857 0.8435 \nCommunication Fachrina 0.9617 0.6279 0.9209 \nGRU-based 0.9523 0.6567 0.9326'
 'classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'price. The average of aspect occurrences in a sentence is 0.98. Each sentiment aspect can be classified as positive or negative. The statistics of the datasets are shown in Table I.  \nB. Experiments \nWe used different settings for different models. For \naspect detection model, the first approach used Adagrad optimizer with learning rate 0.01. We applied weight constraint in dense layer and dropout in recurrent layer. The second approach used Adam optimizer with learning rate 0.00025 and dropout rate 0.5 is applied. We did early \nstopping to both approaches to prevent overfitting. \nBefore performing the whole experiment, we compare \ntwo baselines of aspect model. One should be chosen so two baselines of sentiment classification model could also be compared fairly. Evaluation on aspect detection result is done by comparing average f1-score value which is \nshown at Table II. The fully-connected baseline is inferior'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'the original word vector is passed onto the aspect \nsentiment classification model to get the sentiment class for each aspect. The flow is shown in Figure 1. \n \nFigure 1. Process Flow of the Aspect based Sentiment Analysis \nA. Aspect Detection Model \n Such as mentioned in previous paragraph, there are \ntwo compared approaches in the aspect detection model. The first approach on this model adopts RNN for handling \naspect detection. The input is a word embedding vector \nwhich is calculated by word2vec approach [18]. \n \nFigure 2. First Approach of Aspect Detection Model \nThere are two layers of GRU, where the first GRU \nreturns a sequence of input for the second GRU. We connect the last output state of the second GRU to a fully \nconnected layer with sigmoid activation function. The  \n2018 International Conference on Asian Language Processing (IALP) 63'
 'target aspect well according to some words which we \nhave been analyzed. Although CNN-based sentiment classification could benefit from aspect matrix, GRU-\nbased is still better by using derived features such as \nsentiment lexicons and POS tags.  \nBased on our evaluation, our model achieves state-of-\nthe-art performance on 4 out of 7 aspects. Compared to Fachrina and Widyantoro [7], which use different model for each aspect, our model could generalize well over all \naspects within the dataset.  \nA\nCKNOWLEDGMENT  \nThis work was supported by Prosa.ai. We would also \nlike to thank Fachrina for providing the annotated dataset regarding to this work. \nR\nEFERENCES  \n[1] Pontiki M. et al. SemEval-2014 Task 4: Aspect Based Sentiment \nAnalysis, Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014) pp. 27 - 35, Dublin, Ireland, \nAugust 23-24, 2014.\n \n[2] Pontiki M. et al. SemEval-2015 Task 12: Aspect Based Sentiment'
 'a sentence is predicted not having a certain aspect, its label in that aspect is none. Otherwise, the sentence and the aspect are pipelined to sentiment classification. We compare two approaches in the sentiment classification. The first approach use Bi-GRU to classify the sentiment \nof each aspect resulted by the aspect detection model. It is \nsimilar to aspect-specific sentiment extraction model from Jebbara and Cimiano [14] but we use different features. The other differences are the use of predefined aspects and we do not pay attention to the corresponding terms of aspects. The input layer consists of a set of word vectors \nw\ni which is concatenated with their corresponding \nsentiment embedding si and POS tag pi for each word. The \nsentiment embedding is taken from sentiment lexicon'
 'system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with']","The F1-score of the GRU baseline in the aspect model is 0.8855, while the Fully-Connected baseline has an F1-score of 0.8527. Therefore, the GRU baseline outperforms the Fully-Connected baseline in terms of F1-score.",0.08,0.9765432098656928,1.0,1.0,0.9576099668826629
"How does aspect matrix improve CNN sentiment classification compared to GRU models, considering features like sentiment lexicons and POS tags?","Aspect matrix improves CNN sentiment classification compared to GRU models by using the aspect model to generate an aspect matrix, which rescales the word embedding vector as the input vector. This approach, utilizing CNN-based topology, has shown competitive results compared to previous methods such as SVM and rule-based techniques [1]. Additionally, aspect detection with GRU layers has been found to outperform fully-connected layers, with the aspect matrix providing a better performance compared to general word embedding approaches [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'target aspect well according to some words which we \nhave been analyzed. Although CNN-based sentiment classification could benefit from aspect matrix, GRU-\nbased is still better by using derived features such as \nsentiment lexicons and POS tags.  \nBased on our evaluation, our model achieves state-of-\nthe-art performance on 4 out of 7 aspects. Compared to Fachrina and Widyantoro [7], which use different model for each aspect, our model could generalize well over all \naspects within the dataset.  \nA\nCKNOWLEDGMENT  \nThis work was supported by Prosa.ai. We would also \nlike to thank Fachrina for providing the annotated dataset regarding to this work. \nR\nEFERENCES  \n[1] Pontiki M. et al. SemEval-2014 Task 4: Aspect Based Sentiment \nAnalysis, Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014) pp. 27 - 35, Dublin, Ireland, \nAugust 23-24, 2014.\n \n[2] Pontiki M. et al. SemEval-2015 Task 12: Aspect Based Sentiment'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'to GRU baseline because GRU baseline has advantages on some words which only occur at test dataset by using word embedding. \nTABLE II. F1-score for each baseline of aspect model \nModel Precision Recall F-score \nGRU 0.8936 0.8775 0.8855 \nFully-Connected 0.8367 0.8693 0.8527 \n \nFor sentiment classification model, the first approach \nhas some features as stated before. We did some experiments by using combination of features as shown in Table III. The highest result is obtained with the combination of word embeddings (WE), sentiment lexicons (SL), and POS tags (POS). It can perform well \nfor predicting both positive and negative labels. \nTABLE III. Average weighted F1-score with different features \nFeature Pos Neg Avg \nWE 0.8843 0.6475 0.8547 \nWE+SL 0.8833 0.6543 0.8545 \nWE+POS 0.8850 0.6505 0.8555 \nWE+SL+POS 0.8852 0.6575 0.8563 \n \nThe second approach use setup from Kim [15].'
 'produce probability of every word occurred in every aspect as well. This probability will be used as input in sentiment classification model. Xue and Li [17] use Gated-CNN to do the sentiment classification. The aspect feature controls the propagation of sentiment with aspect \nembedding of the given aspect category. \nWhile in Indonesian, Fachrina and Widyantoro [7] \ndevelop aspect-sentiment classification in opinion mining using the combination of rule-based and machine learning. The algorithm they use for machine learning are \nSVM and naïve bayes classifier. Gojali and Khodra [6] \nuse supervised learning for subjectivity classification. They use naïve bayes classifier and SVM to classify sentences and CRF for information extraction. Ekawati and Khodra [8] build a system consists of three steps: aspect detection, aspect categorization, and sentiment \nclassification. Cahyadi and Khodra [9] build a similar'
 'embedding which is pre-trained on 27 million sentences \nof Indonesian news data. For each word, similarity function would be computed relative to aspect’s name. \nEvaluation done to all aspects in test dataset result which \nis the output of the better aspect model. Table IV shows that using general word embedding does not benefit as much as using the weights on aspect model because aspect model could distinct words related to aspect better. \nTABLE IV. Average weighted F1-s_core with different choice of aspect \nmatrix. \nAspect Matrix Pos Neg Avg \nAspect Model 0.8803 0.6366 0.8535 \nGeneral Word Embedding 0.8540 0.4502 0.8194 \nTABLE V. Evaluation comparison of different methods \nAspect Model Pos Neg Avg \nAccuracy Fachrina 0.9142 0.5333 0.8601 \nGRU-based 0.9260 0.6474 0.8965 \nCNN-based 0.9303 0.6716 0.9044 \nPrice Fachrina 0.9114 0.4000 0.8927 \nGRU-based 0.8571 0.4000 0.8520 \nCNN-based 0.8547 0.2857 0.8435 \nCommunication Fachrina 0.9617 0.6279 0.9209 \nGRU-based 0.9523 0.6567 0.9326'
 'the original word vector is passed onto the aspect \nsentiment classification model to get the sentiment class for each aspect. The flow is shown in Figure 1. \n \nFigure 1. Process Flow of the Aspect based Sentiment Analysis \nA. Aspect Detection Model \n Such as mentioned in previous paragraph, there are \ntwo compared approaches in the aspect detection model. The first approach on this model adopts RNN for handling \naspect detection. The input is a word embedding vector \nwhich is calculated by word2vec approach [18]. \n \nFigure 2. First Approach of Aspect Detection Model \nThere are two layers of GRU, where the first GRU \nreturns a sequence of input for the second GRU. We connect the last output state of the second GRU to a fully \nconnected layer with sigmoid activation function. The  \n2018 International Conference on Asian Language Processing (IALP) 63'
 'with annotation along some baselines for aspect-based sentiment analysis [1,2,3]. The baseline of aspect detection and sentiment classification use SVM. It also had term extraction process which occurs at some domains. The model could benefit from the exact location \nof aspect’s term because polarity tends to be determined \nby near adjective words. Before extracting aspect, sentence could be filtered by subjectivity classifier [10]. Sentence having sentiment must be subjective. Performing subjectivity classifier would decrease objective sentence so aspect detection model could focus more to label other \nthan none aspect, this aspect is present in some models.  978-1-7281-1175-9/18/$31.00 c⃝2018 IEEE 62\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.']",,0.029069767441860465,0.36111111109305555,0.8,1.0,0.9702346932646279
"What unique method was used for Indonesian aspect-based sentiment analysis, and how does it differ from Cahyadi and Khodra's approach?","We divided the process into two modules with a general model of aspect sentiment classification, employing different deep learning models in sentiment classification, specifically RNN and CNN, which differs from Cahyadi and Khodra's approach [9] that used three components [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['known so far, deep learning-based approach has been used only once to solve Indonesian aspect-based sentiment analysis. Different to Cahyadi and Khodra [9], instead of using three components, we chose to divide the process into two modules with a general model of aspect \nsentiment classification. We employ different deep \nlearning models in sentiment classification, RNN and CNN. \nThis paper is organized in the following manner. \nSection 2 discusses related works. Section 3 discusses the proposed method. Section 4 shows the experimental and \nevaluation results. Finally, the conclusion and future \nworks are in section 5. \nII. R\nELATED WORKS  \nIn this section, we present some previous works which \nare related on aspect-based sentiment analysis. In 2014, \n2015, and 2016, the Semantic Evaluation provided dataset'
 'detection; sentiment classification; Indonesian; deep neural \nnetwork \nI.  INTRODUCTION  \nSentiment analysis is becoming one of the important \ntopics in natural language processing (NLP). It identifies \nand extracts subjective information then classifies them into three following polarities: positive, negative, and neutral. However, regular sentiment analysis can only identify one polarity for each sentence. Whereas it is possible that one sentence can have different sentiment \npolarities at once. For such reason, aspect-based sentiment \nanalysis is needed. \nAspect-based sentiment analysis is a task to find the \nsentiment polarity of each predefined aspects which expressed in a document. The sentiment polarity of a \nsentence is dependent on both content and aspect. For \nexample, in the sentence “The food is delicious, but the \nservice is too slow.”, the expected sentiment polarity of'
 'Aspect Detection and Sentim ent Classification using Deep Neural Network for \nIndonesian Aspect-Based Sentiment Analysis\nArfinda Ilmania \nProsa Solusi Cerdas \nBandung, Indonesia \narfinda.ilmania@prosa.ai \n \nSamuel Cahyawijaya \nProsa Solusi Cerdas  \nBandung, Indonesia \nsamuel.cahyawijaya@prosa.ai Abdurrahman \nProsa Solusi Cerdas  \nBandung, Indonesia \nabdurrahman.prasetyo@prosa.ai \n \nAyu Purwarianti \nInstitut Teknologi Bandung  \nBandung, Indonesia \nayu@stei.itb.ac.id\nAbstract —Sentiment analysis can categorize an overall \nopinion from a sentence or a document. However, there are sentences with more than one opinion in a single sentence \nstatement. This problem is solved by aspect-based sentiment \nanalysis. We conduct experiments on this problem using Indonesian dataset with 2-step process: aspect detection and sentiment classification. On aspect detection, we compare \ntwo deep neural network models with different input vector'
 'produce probability of every word occurred in every aspect as well. This probability will be used as input in sentiment classification model. Xue and Li [17] use Gated-CNN to do the sentiment classification. The aspect feature controls the propagation of sentiment with aspect \nembedding of the given aspect category. \nWhile in Indonesian, Fachrina and Widyantoro [7] \ndevelop aspect-sentiment classification in opinion mining using the combination of rule-based and machine learning. The algorithm they use for machine learning are \nSVM and naïve bayes classifier. Gojali and Khodra [6] \nuse supervised learning for subjectivity classification. They use naïve bayes classifier and SVM to classify sentences and CRF for information extraction. Ekawati and Khodra [8] build a system consists of three steps: aspect detection, aspect categorization, and sentiment \nclassification. Cahyadi and Khodra [9] build a similar'
 '‘food’ and ‘service’ aspects are positive and negative respectively.  Data can be extracted from any sources like \nwebsites, newspapers, or social media. However, extracting the sentiment polarity from these sources is not \neasy. Many contests are held to solve this kind of problem such as, task 4 in SemEval-2014 (SE-ABSA14) [1], task \n12 in SemEval-2015 (SE-ABSA15) [2], and task 5 in \nSemEval-2016 (SE-ABSA16) [3]. Many approaches are used, from traditional model into more complex one like deep neural network.  \nRecently, deep learning-based approach has become a \npowerful technique to address this problem, such as Long \nShort-Term Memory [4], GRU [5], and CNN. However, there have been a few studies conducted to solve this problem in Indonesian language. Some of them use Support Vector Machine (SVM) and Naïve Bayes Classifier [6, 7]. Ekawati and Khodra [8] uses Conditional \nRandom Field (CRF). Based on the research we have'
 'system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'target aspect well according to some words which we \nhave been analyzed. Although CNN-based sentiment classification could benefit from aspect matrix, GRU-\nbased is still better by using derived features such as \nsentiment lexicons and POS tags.  \nBased on our evaluation, our model achieves state-of-\nthe-art performance on 4 out of 7 aspects. Compared to Fachrina and Widyantoro [7], which use different model for each aspect, our model could generalize well over all \naspects within the dataset.  \nA\nCKNOWLEDGMENT  \nThis work was supported by Prosa.ai. We would also \nlike to thank Fachrina for providing the annotated dataset regarding to this work. \nR\nEFERENCES  \n[1] Pontiki M. et al. SemEval-2014 Task 4: Aspect Based Sentiment \nAnalysis, Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014) pp. 27 - 35, Dublin, Ireland, \nAugust 23-24, 2014.\n \n[2] Pontiki M. et al. SemEval-2015 Task 12: Aspect Based Sentiment'
 'Classification in Opinion Mining using the Combination of Rule-Based and Machine Learning”. International Conference on Data \nand Software Engineering (ICoDSE) , Palembang, 2017, pp. 1-6.\n [8] Ekawati D. and Khodra M. L., “Aspect-Based Sentiment Analysis \nfor Indonesian Restaurant Reviews,” in Advanced Informatics: \nConcepts, Theory and Application (ICAICTA), 2017.  \n[9] Cahyadi A. and Khodra M. L., “Aspect-Based Sentiment Analysis \nUsing Convolutional Neural Network and Bidirectional Long \nShort-Term Memory” in Advanced Informatics: Concepts, Theory and Application (ICAICTA), 2018.\n \n[10] Liu, B. “Sentiment analysis and subjectivity”. In Handbook of \nNatural Language Processing, Second Edition, N. Indurkhya and \nF.J. Damerau, Editors. 2010.  \n[11] Tang, D., Qin, B., Feng, X., and Liu, T. “Target-Dependent \nSentiment Classification with Long-Short Term Memory”. CoRR, abs/1512.01100, 2015.\n \n[12] Wang, Y., Huang, M., Zhu, X., and Zhao, L. “Attention-Based'
 'Compositionality. Accepted to NIPS 2013.  \n[19] Wahid, D. H., and Azhari, S. N. “Peringkasan Sentimen Ekstraktif \ndi Twitter Men ggunakan Hybrid TF-IDF dan Cosine Similarity”. \nIJCCS (Indonesian Journal of Computing and Cybernetics \nSystems), 10(2), 207-218, 2016.  \n[20] Liu, Bing, Hu, Minqing, and Cheng, Junsheng. ""Opinion Observer: \nAnalyzing and Comparing Opinions on the Web."" Proceedings of \nthe 14th International World Wide Web Conference (WWW-\n2005), May 10-14, Chiba, Japan, 2005.  \n[21] Purwarianti, A., Gunarso, Suhardijanto, T. F. “INACL POS \nTagging Convention Konvensi Pelabelan Kelas Kata \nINACL/MALKIN,” 2017.\n 2018 International Conference on Asian Language Processing (IALP) 67\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.']","A deep learning-based approach was used for Indonesian aspect-based sentiment analysis, which differed from Cahyadi and Khodra's approach by dividing the process into two modules with a general model of aspect sentiment classification and employing different deep learning models such as RNN and CNN.",0.010582010582010581,0.99999999999,1.0,1.0,0.8710797272975195
How does aspect-based sentiment analysis in the Indonesian study improve sentiment polarity determination over traditional methods?,"Aspect-based sentiment analysis in the Indonesian study improves sentiment polarity determination over traditional methods by focusing on identifying the sentiment polarity of predefined aspects expressed in a document. This approach considers both the content and aspect of a sentence to determine sentiment polarity accurately. Traditional sentiment analysis may only identify one polarity for each sentence, while aspect-based sentiment analysis can capture multiple sentiment polarities within a single sentence, leading to more nuanced and precise results [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['detection; sentiment classification; Indonesian; deep neural \nnetwork \nI.  INTRODUCTION  \nSentiment analysis is becoming one of the important \ntopics in natural language processing (NLP). It identifies \nand extracts subjective information then classifies them into three following polarities: positive, negative, and neutral. However, regular sentiment analysis can only identify one polarity for each sentence. Whereas it is possible that one sentence can have different sentiment \npolarities at once. For such reason, aspect-based sentiment \nanalysis is needed. \nAspect-based sentiment analysis is a task to find the \nsentiment polarity of each predefined aspects which expressed in a document. The sentiment polarity of a \nsentence is dependent on both content and aspect. For \nexample, in the sentence “The food is delicious, but the \nservice is too slow.”, the expected sentiment polarity of'
 'Aspect Detection and Sentim ent Classification using Deep Neural Network for \nIndonesian Aspect-Based Sentiment Analysis\nArfinda Ilmania \nProsa Solusi Cerdas \nBandung, Indonesia \narfinda.ilmania@prosa.ai \n \nSamuel Cahyawijaya \nProsa Solusi Cerdas  \nBandung, Indonesia \nsamuel.cahyawijaya@prosa.ai Abdurrahman \nProsa Solusi Cerdas  \nBandung, Indonesia \nabdurrahman.prasetyo@prosa.ai \n \nAyu Purwarianti \nInstitut Teknologi Bandung  \nBandung, Indonesia \nayu@stei.itb.ac.id\nAbstract —Sentiment analysis can categorize an overall \nopinion from a sentence or a document. However, there are sentences with more than one opinion in a single sentence \nstatement. This problem is solved by aspect-based sentiment \nanalysis. We conduct experiments on this problem using Indonesian dataset with 2-step process: aspect detection and sentiment classification. On aspect detection, we compare \ntwo deep neural network models with different input vector'
 'known so far, deep learning-based approach has been used only once to solve Indonesian aspect-based sentiment analysis. Different to Cahyadi and Khodra [9], instead of using three components, we chose to divide the process into two modules with a general model of aspect \nsentiment classification. We employ different deep \nlearning models in sentiment classification, RNN and CNN. \nThis paper is organized in the following manner. \nSection 2 discusses related works. Section 3 discusses the proposed method. Section 4 shows the experimental and \nevaluation results. Finally, the conclusion and future \nworks are in section 5. \nII. R\nELATED WORKS  \nIn this section, we present some previous works which \nare related on aspect-based sentiment analysis. In 2014, \n2015, and 2016, the Semantic Evaluation provided dataset'
 '‘food’ and ‘service’ aspects are positive and negative respectively.  Data can be extracted from any sources like \nwebsites, newspapers, or social media. However, extracting the sentiment polarity from these sources is not \neasy. Many contests are held to solve this kind of problem such as, task 4 in SemEval-2014 (SE-ABSA14) [1], task \n12 in SemEval-2015 (SE-ABSA15) [2], and task 5 in \nSemEval-2016 (SE-ABSA16) [3]. Many approaches are used, from traditional model into more complex one like deep neural network.  \nRecently, deep learning-based approach has become a \npowerful technique to address this problem, such as Long \nShort-Term Memory [4], GRU [5], and CNN. However, there have been a few studies conducted to solve this problem in Indonesian language. Some of them use Support Vector Machine (SVM) and Naïve Bayes Classifier [6, 7]. Ekawati and Khodra [8] uses Conditional \nRandom Field (CRF). Based on the research we have'
 'produce probability of every word occurred in every aspect as well. This probability will be used as input in sentiment classification model. Xue and Li [17] use Gated-CNN to do the sentiment classification. The aspect feature controls the propagation of sentiment with aspect \nembedding of the given aspect category. \nWhile in Indonesian, Fachrina and Widyantoro [7] \ndevelop aspect-sentiment classification in opinion mining using the combination of rule-based and machine learning. The algorithm they use for machine learning are \nSVM and naïve bayes classifier. Gojali and Khodra [6] \nuse supervised learning for subjectivity classification. They use naïve bayes classifier and SVM to classify sentences and CRF for information extraction. Ekawati and Khodra [8] build a system consists of three steps: aspect detection, aspect categorization, and sentiment \nclassification. Cahyadi and Khodra [9] build a similar'
 'with annotation along some baselines for aspect-based sentiment analysis [1,2,3]. The baseline of aspect detection and sentiment classification use SVM. It also had term extraction process which occurs at some domains. The model could benefit from the exact location \nof aspect’s term because polarity tends to be determined \nby near adjective words. Before extracting aspect, sentence could be filtered by subjectivity classifier [10]. Sentence having sentiment must be subjective. Performing subjectivity classifier would decrease objective sentence so aspect detection model could focus more to label other \nthan none aspect, this aspect is present in some models.  978-1-7281-1175-9/18/$31.00 c⃝2018 IEEE 62\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'target aspect well according to some words which we \nhave been analyzed. Although CNN-based sentiment classification could benefit from aspect matrix, GRU-\nbased is still better by using derived features such as \nsentiment lexicons and POS tags.  \nBased on our evaluation, our model achieves state-of-\nthe-art performance on 4 out of 7 aspects. Compared to Fachrina and Widyantoro [7], which use different model for each aspect, our model could generalize well over all \naspects within the dataset.  \nA\nCKNOWLEDGMENT  \nThis work was supported by Prosa.ai. We would also \nlike to thank Fachrina for providing the annotated dataset regarding to this work. \nR\nEFERENCES  \n[1] Pontiki M. et al. SemEval-2014 Task 4: Aspect Based Sentiment \nAnalysis, Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014) pp. 27 - 35, Dublin, Ireland, \nAugust 23-24, 2014.\n \n[2] Pontiki M. et al. SemEval-2015 Task 12: Aspect Based Sentiment']","Aspect-based sentiment analysis in the Indonesian study improves sentiment polarity determination over traditional methods by considering predefined aspects expressed in a document. This approach recognizes that one sentence can have different sentiment polarities at once, unlike regular sentiment analysis that can only identify one polarity per sentence. By analyzing both content and aspect, the sentiment polarity of each aspect can be accurately determined, as demonstrated in the example sentence 'The food is delicious, but the service is too slow.'",0.05555555555555555,0.99999999999,1.0,1.0,0.9431273586307812
"How do the two sentiment classification approaches differ in terms of aspect-specific sentiment extraction and feature utilization, with Bi-GRU for sentiment classification and deep learning for aspect detection?","Aspect-specific sentiment extraction and feature utilization differ between the two sentiment classification approaches mentioned in the context. The first approach involves using Bi-GRU for sentiment classification, where the input vector includes word embedding, sentiment lexicon, and POS tags, with a bi-GRU-based topology. On the other hand, the second approach utilizes deep learning for aspect detection, with the input vector being rescaled by an aspect matrix and a convolutional neural network (CNN) based topology. Both approaches show competitive results compared to previous methods, with the aspect matrix approach outperforming a general word embedding approach [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'known so far, deep learning-based approach has been used only once to solve Indonesian aspect-based sentiment analysis. Different to Cahyadi and Khodra [9], instead of using three components, we chose to divide the process into two modules with a general model of aspect \nsentiment classification. We employ different deep \nlearning models in sentiment classification, RNN and CNN. \nThis paper is organized in the following manner. \nSection 2 discusses related works. Section 3 discusses the proposed method. Section 4 shows the experimental and \nevaluation results. Finally, the conclusion and future \nworks are in section 5. \nII. R\nELATED WORKS  \nIn this section, we present some previous works which \nare related on aspect-based sentiment analysis. In 2014, \n2015, and 2016, the Semantic Evaluation provided dataset'
 'the original word vector is passed onto the aspect \nsentiment classification model to get the sentiment class for each aspect. The flow is shown in Figure 1. \n \nFigure 1. Process Flow of the Aspect based Sentiment Analysis \nA. Aspect Detection Model \n Such as mentioned in previous paragraph, there are \ntwo compared approaches in the aspect detection model. The first approach on this model adopts RNN for handling \naspect detection. The input is a word embedding vector \nwhich is calculated by word2vec approach [18]. \n \nFigure 2. First Approach of Aspect Detection Model \nThere are two layers of GRU, where the first GRU \nreturns a sequence of input for the second GRU. We connect the last output state of the second GRU to a fully \nconnected layer with sigmoid activation function. The  \n2018 International Conference on Asian Language Processing (IALP) 63'
 'a sentence is predicted not having a certain aspect, its label in that aspect is none. Otherwise, the sentence and the aspect are pipelined to sentiment classification. We compare two approaches in the sentiment classification. The first approach use Bi-GRU to classify the sentiment \nof each aspect resulted by the aspect detection model. It is \nsimilar to aspect-specific sentiment extraction model from Jebbara and Cimiano [14] but we use different features. The other differences are the use of predefined aspects and we do not pay attention to the corresponding terms of aspects. The input layer consists of a set of word vectors \nw\ni which is concatenated with their corresponding \nsentiment embedding si and POS tag pi for each word. The \nsentiment embedding is taken from sentiment lexicon'
 'detection; sentiment classification; Indonesian; deep neural \nnetwork \nI.  INTRODUCTION  \nSentiment analysis is becoming one of the important \ntopics in natural language processing (NLP). It identifies \nand extracts subjective information then classifies them into three following polarities: positive, negative, and neutral. However, regular sentiment analysis can only identify one polarity for each sentence. Whereas it is possible that one sentence can have different sentiment \npolarities at once. For such reason, aspect-based sentiment \nanalysis is needed. \nAspect-based sentiment analysis is a task to find the \nsentiment polarity of each predefined aspects which expressed in a document. The sentiment polarity of a \nsentence is dependent on both content and aspect. For \nexample, in the sentence “The food is delicious, but the \nservice is too slow.”, the expected sentiment polarity of'
 'Aspect Detection and Sentim ent Classification using Deep Neural Network for \nIndonesian Aspect-Based Sentiment Analysis\nArfinda Ilmania \nProsa Solusi Cerdas \nBandung, Indonesia \narfinda.ilmania@prosa.ai \n \nSamuel Cahyawijaya \nProsa Solusi Cerdas  \nBandung, Indonesia \nsamuel.cahyawijaya@prosa.ai Abdurrahman \nProsa Solusi Cerdas  \nBandung, Indonesia \nabdurrahman.prasetyo@prosa.ai \n \nAyu Purwarianti \nInstitut Teknologi Bandung  \nBandung, Indonesia \nayu@stei.itb.ac.id\nAbstract —Sentiment analysis can categorize an overall \nopinion from a sentence or a document. However, there are sentences with more than one opinion in a single sentence \nstatement. This problem is solved by aspect-based sentiment \nanalysis. We conduct experiments on this problem using Indonesian dataset with 2-step process: aspect detection and sentiment classification. On aspect detection, we compare \ntwo deep neural network models with different input vector'
 'to GRU baseline because GRU baseline has advantages on some words which only occur at test dataset by using word embedding. \nTABLE II. F1-score for each baseline of aspect model \nModel Precision Recall F-score \nGRU 0.8936 0.8775 0.8855 \nFully-Connected 0.8367 0.8693 0.8527 \n \nFor sentiment classification model, the first approach \nhas some features as stated before. We did some experiments by using combination of features as shown in Table III. The highest result is obtained with the combination of word embeddings (WE), sentiment lexicons (SL), and POS tags (POS). It can perform well \nfor predicting both positive and negative labels. \nTABLE III. Average weighted F1-score with different features \nFeature Pos Neg Avg \nWE 0.8843 0.6475 0.8547 \nWE+SL 0.8833 0.6543 0.8545 \nWE+POS 0.8850 0.6505 0.8555 \nWE+SL+POS 0.8852 0.6575 0.8563 \n \nThe second approach use setup from Kim [15].']","The two sentiment classification approaches differ in terms of aspect-specific sentiment extraction and feature utilization. The first approach uses Bi-GRU for sentiment classification, while the second approach utilizes deep learning for aspect detection. The first approach is similar to aspect-specific sentiment extraction model from Jebbara and Cimiano [14] but with different features. Additionally, the first approach uses predefined aspects and does not focus on corresponding terms of aspects. On the other hand, the second approach focuses on aspect detection using deep learning techniques.",0.028089887640449437,0.99999999999,1.0,1.0,0.8943936282232571
How does aspect matrix improve CNN sentiment classification compared to GRU models with sentiment lexicons and POS tags?,"Aspect matrix improves CNN sentiment classification compared to GRU models with sentiment lexicons and POS tags by rescaling the word vector of the input sentence using a dense layer for the bag of words input layer. Aspect detection with GRU layers outperforms fully-connected layers, generating a matrix denoting the probability of each word given an aspect. Utilizing the aspect model to create an aspect matrix yields better performance than a general word embedding approach [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['classification. The second one employs aspect matrix to rescale the word vector of input sentence which aspect matrix is resulted by using dense layer for bag of words input layer. Both approaches obtain competitive result compared to previous research on Indonesian aspect based \nsentiment analysis using SVM and rule based methods \n[7]. \nFrom our experiments, we derive the following \nconclusions. Aspect detection with GRU layers performs better than fully-connected layer. Additional output from aspect detection is a matrix which denote probability of \neach word given an aspect. Using aspect model to \ngenerate aspect matrix gives a better performance compared to a general word embedding approach. The aspect matrix could distinct same sentence with different 2018 International Conference on Asian Language Processing (IALP) 66\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'target aspect well according to some words which we \nhave been analyzed. Although CNN-based sentiment classification could benefit from aspect matrix, GRU-\nbased is still better by using derived features such as \nsentiment lexicons and POS tags.  \nBased on our evaluation, our model achieves state-of-\nthe-art performance on 4 out of 7 aspects. Compared to Fachrina and Widyantoro [7], which use different model for each aspect, our model could generalize well over all \naspects within the dataset.  \nA\nCKNOWLEDGMENT  \nThis work was supported by Prosa.ai. We would also \nlike to thank Fachrina for providing the annotated dataset regarding to this work. \nR\nEFERENCES  \n[1] Pontiki M. et al. SemEval-2014 Task 4: Aspect Based Sentiment \nAnalysis, Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014) pp. 27 - 35, Dublin, Ireland, \nAugust 23-24, 2014.\n \n[2] Pontiki M. et al. SemEval-2015 Task 12: Aspect Based Sentiment'
 'result in SemEval-ABSA. Another approach by Jebbara and Cimiano [14] uses two models to extract aspect terms and determine their polarity. They use bidirectional GRU and a fully connected layer for each model, but they put many features for the input. They also use semantic \nresources like SenticNet and WordNet. Their approach \nobtained the best result on task 2 in ESCW 2016 Challenge for Semantic Sentiment Analysis and became the most innovative approach. \nAnother approach on accomplishing NLP task using \ndeep learning is CNN. The problems involve polarity \nclassification on various reviews, subjectivity classification, question type classification which are done by Kim [15]. The main reference we used to build CNN-based deep learning baseline to solve aspect-based sentiment analysis is Wang and Liu [16]. The aspect \nclassification not only produce predicted aspects but'
 'system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'produce probability of every word occurred in every aspect as well. This probability will be used as input in sentiment classification model. Xue and Li [17] use Gated-CNN to do the sentiment classification. The aspect feature controls the propagation of sentiment with aspect \nembedding of the given aspect category. \nWhile in Indonesian, Fachrina and Widyantoro [7] \ndevelop aspect-sentiment classification in opinion mining using the combination of rule-based and machine learning. The algorithm they use for machine learning are \nSVM and naïve bayes classifier. Gojali and Khodra [6] \nuse supervised learning for subjectivity classification. They use naïve bayes classifier and SVM to classify sentences and CRF for information extraction. Ekawati and Khodra [8] build a system consists of three steps: aspect detection, aspect categorization, and sentiment \nclassification. Cahyadi and Khodra [9] build a similar'
 'to GRU baseline because GRU baseline has advantages on some words which only occur at test dataset by using word embedding. \nTABLE II. F1-score for each baseline of aspect model \nModel Precision Recall F-score \nGRU 0.8936 0.8775 0.8855 \nFully-Connected 0.8367 0.8693 0.8527 \n \nFor sentiment classification model, the first approach \nhas some features as stated before. We did some experiments by using combination of features as shown in Table III. The highest result is obtained with the combination of word embeddings (WE), sentiment lexicons (SL), and POS tags (POS). It can perform well \nfor predicting both positive and negative labels. \nTABLE III. Average weighted F1-score with different features \nFeature Pos Neg Avg \nWE 0.8843 0.6475 0.8547 \nWE+SL 0.8833 0.6543 0.8545 \nWE+POS 0.8850 0.6505 0.8555 \nWE+SL+POS 0.8852 0.6575 0.8563 \n \nThe second approach use setup from Kim [15].'
 'embedding which is pre-trained on 27 million sentences \nof Indonesian news data. For each word, similarity function would be computed relative to aspect’s name. \nEvaluation done to all aspects in test dataset result which \nis the output of the better aspect model. Table IV shows that using general word embedding does not benefit as much as using the weights on aspect model because aspect model could distinct words related to aspect better. \nTABLE IV. Average weighted F1-s_core with different choice of aspect \nmatrix. \nAspect Matrix Pos Neg Avg \nAspect Model 0.8803 0.6366 0.8535 \nGeneral Word Embedding 0.8540 0.4502 0.8194 \nTABLE V. Evaluation comparison of different methods \nAspect Model Pos Neg Avg \nAccuracy Fachrina 0.9142 0.5333 0.8601 \nGRU-based 0.9260 0.6474 0.8965 \nCNN-based 0.9303 0.6716 0.9044 \nPrice Fachrina 0.9114 0.4000 0.8927 \nGRU-based 0.8571 0.4000 0.8520 \nCNN-based 0.8547 0.2857 0.8435 \nCommunication Fachrina 0.9617 0.6279 0.9209 \nGRU-based 0.9523 0.6567 0.9326'
 'the original word vector is passed onto the aspect \nsentiment classification model to get the sentiment class for each aspect. The flow is shown in Figure 1. \n \nFigure 1. Process Flow of the Aspect based Sentiment Analysis \nA. Aspect Detection Model \n Such as mentioned in previous paragraph, there are \ntwo compared approaches in the aspect detection model. The first approach on this model adopts RNN for handling \naspect detection. The input is a word embedding vector \nwhich is calculated by word2vec approach [18]. \n \nFigure 2. First Approach of Aspect Detection Model \nThere are two layers of GRU, where the first GRU \nreturns a sequence of input for the second GRU. We connect the last output state of the second GRU to a fully \nconnected layer with sigmoid activation function. The  \n2018 International Conference on Asian Language Processing (IALP) 63'
 'with annotation along some baselines for aspect-based sentiment analysis [1,2,3]. The baseline of aspect detection and sentiment classification use SVM. It also had term extraction process which occurs at some domains. The model could benefit from the exact location \nof aspect’s term because polarity tends to be determined \nby near adjective words. Before extracting aspect, sentence could be filtered by subjectivity classifier [10]. Sentence having sentiment must be subjective. Performing subjectivity classifier would decrease objective sentence so aspect detection model could focus more to label other \nthan none aspect, this aspect is present in some models.  978-1-7281-1175-9/18/$31.00 c⃝2018 IEEE 62\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.']",,0.011627906976744186,0.36111111109907407,1.0,1.0,0.972595347277221
How is the sentiment lexicon used in the sentiment classification model with word sentiment values and POS tagging in the two approaches?,"The sentiment lexicon is utilized in the sentiment classification model with word sentiment values and POS tagging in two approaches. In the first approach, the input vector includes word embedding, sentiment lexicon, and POS tags, with a bi-GRU based topology. The second approach involves using an aspect matrix to rescale the word embedding vector as the input vector, with a convolutional neural network (CNN) based topology [1].

References:
[1] Arfinda Ilmania, Samuel Cahyawijaya, Abdurrahman, and Ayu Purwarianti, ""Aspect Detection and Sentiment Classification using Deep Neural Network for Indonesian Aspect-Based Sentiment Analysis,"" *IEEE Transactions on Smart Grid*, Mar. 2014.","['The second approach of sentiment classification \nmodel, as given in Figure 5, receives word vectors which  \n2018 International Conference on Asian Language Processing (IALP) 64\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'and topology: word embedding vector which is processed using gated recurrent unit (GRU), and bag-of-words vector which is processed using fully-connected layer. On sentiment \nclassification, we also compare two approaches of deep \nneural network. The first approach uses word embedding, sentiment lexicon and POS tags as the input vector, with bi-GRU based as the topology. The second one uses aspect \nmatrix to rescale the word embedding vector as the input \nvector and convolutional neural network (CNN) based as the topology. Our work is compared to a baseline framework which uses different model for each aspect. The dataset has approximately 9800 reviews collected from various \ncategories on popular online marketplaces in Indonesia.  \nOur models generalize well over all aspects and achieve state-of-the-art performance on  4 out of 7 aspects compared \nto the baseline framework. \nKeywords- aspect-based; sentiment analysis; aspect'
 'sentiment analysis method uses only the words which aren’t a \npart of speech such as article and interrogative. In the preprocess, \nwe remove useless words and use only adjective, adverb, \ncommon noun, and verb. It is known that if useless words aren’t \nremoved sufficiently and a part of them remain, then the results \nof a sentiment classification becomes worse. \nThe second phase of our method is a sentiments extraction \nof words. Figure 2 shows the process of the second phase by \nexemplifying a word “Love” which is obtained as a part of \noutputs from the morphological analysis.  At first, all words \nwhich have a similarity to the original word “Love” are detected \nby using a corpus. In order to calculate word similarity, we use \nan open-source library “fastText” and word vectors models \ntrained on corpora such as “Common Crawl” and “Wikipedia” \n[12]. The library “fastText” is used for learning of text \nclassification and word embedding. The word vectors model is'
 'system and make a new approach by using deep learning on aspect detection and sentiment classification. The number of models used on sentiment classification is as many as the number of predefined aspects. \nIII. A\nSPECT -BASED SENTIMENT ANALYSIS  \nBasically, our system consists of two models: aspect \ndetection and sentiment classification. In both models, we compared  two approaches each. In the aspect detection \nmodel, we compared  the one using GRU based aspect classification with word embedding vector as the input \nlayer, and bag-of-word vector input as the input layer with aim to get additional output of word weight. The first \napproach is common technique for text classification with \ndeep learning approach, whil e the second approach is \nsimilar with Wang. The input for both approaches is taken from the pre-processing module which consists of word normalization, tokenization, and punctuation-symbol deletion. The result of aspect detection model along with'
 'the information by using our method. III. SENTIMENT CLASSIFICATION EXPERIMENT  \nIn order to evaluate the performance of our sentiment \nclassifier, we conduct a classification  experiment of sentiment \ninformation from tweet texts in four languages, English, German, \nFrench, and Spanish. In this section, two previous sentiment \nclassifiers “Valence Aware Dictionary for Sentiment Reasoning” \n(“VADER”, for short) and “Google Cloud Platform” (“GCP”, \nfor short) are described to compare the performance with them. \nFig.  2. Procedure to calculate the sentiment for each word. \nFig.  3. Classification rule on the sentiment analysis method. \n76\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 '(similar approach with Do [13]) which consists of words with positive and negative sentiment value. The sentiment lexicon is translated by Wahid and Azhari [19] from Hu and Liu [20]. Each word is represented by one-hot encoded vector s\ni according to its sentiment polarity. \nWhen a word has no sentiment polarity (positive or \nnegative) it will be represented as ‘others’. For the POS tag, we employed POS tagger provided in prosa.ai which uses INACL standard POS tag list with 26 POS tags [21]. \nFigure 4. First Approach of Sentiment Classification Model \nBefore converting word into vector, we decided to add \nthe corresponding aspects to the beginning of the sentences. We managed it so that sentences can only have \none aspect. As a result of doing this, the sentence which \ncontain more than one aspect need to be processed as many as the number of the aspects. For example, in the sentence: “Kualitas oke, cepat, ramah, terima kasih \nbanyak”  (“Good quality, fast, friendly, thank you so'
 'adopted as an expression of the meaning of each word. Secondly, \nthe similar words are translated into native language by a \ntranslation system “Google Translate”. In our method, the \ncorpus and the word-to-word dictionary are the only two \nnecessary knowledges about the language of the input text. \x03\nThirdly, some words are extracted from the set of words \nobtained by the translation. As shown in Figure 2, the original \nword “Love” and each word obtained by translating the word are \npaired up, and an average value of vectors is calculated from the \nvector of the pair. Words are extracted as the high similarity \nwords in descending order of the average values. Fourthly, \nsentiments of each pair are classified by a sentiment dictionary \nFig.  1. Outline of a multilingual sentiment analysis method. \n \n75\nAuthorized licensed use limited to: University of the Philippines - Los Banos. Downloaded on April 30,2024 at 20:17:59 UTC from IEEE Xplore.  Restrictions apply.'
 'to GRU baseline because GRU baseline has advantages on some words which only occur at test dataset by using word embedding. \nTABLE II. F1-score for each baseline of aspect model \nModel Precision Recall F-score \nGRU 0.8936 0.8775 0.8855 \nFully-Connected 0.8367 0.8693 0.8527 \n \nFor sentiment classification model, the first approach \nhas some features as stated before. We did some experiments by using combination of features as shown in Table III. The highest result is obtained with the combination of word embeddings (WE), sentiment lexicons (SL), and POS tags (POS). It can perform well \nfor predicting both positive and negative labels. \nTABLE III. Average weighted F1-score with different features \nFeature Pos Neg Avg \nWE 0.8843 0.6475 0.8547 \nWE+SL 0.8833 0.6543 0.8545 \nWE+POS 0.8850 0.6505 0.8555 \nWE+SL+POS 0.8852 0.6575 0.8563 \n \nThe second approach use setup from Kim [15].'
 'analysis is needed for texts in various languages. However, the \nclassifier needs to be improved on the performance for practical \nuse. Main reason of no significant performance is lack of \nconsideration for contextual weight of sentimental words. For \nexample, “hate” is strong sentimental degree than “like”. In this \nresearch, the sentiment weights have not been considered in our \nclassification. In order to improve the score of the performance \nof the classifier, we have to introduce syntactic parser to the \nclassification process.  \nV. CONCLUSION AND FUTURE RESEARCH  \nWe proposed a multilingual sentiment analysis method \nbased on word to word translation using a sentiment dictionary, \nand evaluated the performance by comparing it with the \nprevious classifiers “VADER” and “GCP”. It was shown that \nour classifier has an advantage of low costs in the process of language translations, because it estimates sentiment values for \neach sentence by using only the word to word translation'
 'A. Previous Sentiment Classifiers \nTwo sentiment classifiers are used in an experiment for \nmaking comparisons with our classifier. The one is called \n“VADER”, which is a simple rule-based model for general \nsentiment analysis from “Natural Language Toolkit” (“NLTK”, \nfor short) [14]. “VADER” is well-known to be an especially \nsuitable sentiment analysis method for microblog-like context \n(e.g. Tweets). Before using “VADER” in our experiment, we \nneed to translate tweets into English texts. The performance of \n“VADER” can be considered to become lower if translation \nprocess is omitted in the preprocess, because “VADER” on \n“NLTK” focuses on sentiment classification for English texts. \n“VADER” returns a real value named “compound” in the range \nfrom –1 to +1 instead of sentiment categories such as “Positive” \nand “Negative”. Typically, the value close to –1 is supposed to \nbe negative sentiment, and the value close to +1 is supposed to']","The sentiment lexicon is translated by Wahid and Azhari from Hu and Liu. Each word is represented by a one-hot encoded vector according to its sentiment polarity. When a word has no sentiment polarity, it is represented as 'others'. The POS tagger provided by prosa.ai is used with 26 POS tags. Before converting words into vectors, the corresponding aspects are added to the beginning of the sentences. This allows sentences to have only one aspect, requiring multiple processing for sentences with more than one aspect.",0.027777777777777776,0.99999999999,1.0,1.0,0.9224431906228809
